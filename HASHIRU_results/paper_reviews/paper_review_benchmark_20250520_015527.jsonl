{"paper_id": "oze0clVGPeX", "prompt_snippet": "Create THREE agents with relevant personalities, expertise, and review styles. Each agent should provide a review of the paper, and recommend Accept/Reject for ICLR 2023. The review should be detailed", "agent_review": [{"role": "user", "content": "Create THREE agents with relevant personalities, expertise, and review styles. Each agent should provide a review of the paper, and recommend Accept/Reject for ICLR 2023. The review should be detailed and include strengths and weaknesses. Finish the entire review and DO NOT STOP in the middle. GIVE A FINAL DECISION in the form of \"FINAL DECISION: <Accept/Reject>\". The paper title is: Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping\n\n1 INTRODUCTION: Recent works on deep learning with differential privacy (DP) have substantially improved the computational efficiency (Subramani et al., 2021; Anil et al., 2021) and privacy-utility trade-off (Li et al., 2022a; Yu et al., 2022; De et al., 2022; Mehta et al., 2022), resulting in cost-effective private learning workflows with favourable utility under common levels of privacy guarantee. Common to most of these works is the use of differentially private stochastic gradient descent (DP-SGD) which clips per-example gradients (herein referred to as flat clipping) and noises their average before performing the parameter update based on a minibatch (Song et al., 2013; Bassily et al., 2014; Abadi et al., 2016). We explore whether further improvements in computational efficiency and privacy-utility trade-off are possible and provide affirmative answers for both directions, leveraging two instantiations of group-wise clipping for DP-SGD. DP-SGD is known to be computationally costly due to clipping per-example gradients. Instantiating per-example gradients and (potentially) normalizing them can incur both high memory and time costs in standard machine learning frameworks (Paszke et al., 2019; Frostig et al., 2018), and thus private machine learning with DP-SGD is reportedly much more memory demanding and/or slower than its non-private counterpart (Carlini et al., 2019; Hoory et al., 2021). Recent works have considerably improved the memory and time efficiency of DP-SGD with better software primitives (Subramani et al., 2021) and algorithms (Yousefpour et al., 2021; Lee & Kifer, 2021; Li et al., 2022b; Bu et al., 2022). Nevertheless, private learning still shows non-trivial increases in either memory usage or compute time when compared to non-private learning head-to-head. For instance, better software primitives do not eliminate the inherent increase in memory spending (Subramani et al., 2021), and improved algorithms only remove this memory overhead at the cost of extra runtime (Li et al., 2022b). The first research question we study is therefore Can private learning be as memory and time efficient (per-epoch) as non-private learning? We answer the above question affirmatively by giving an efficient implementation of per-layer clipping which had been studied in past works but not from a computational efficiency perspective (McMahan et al., 2018b; Dupuy et al., 2022). Clipping per-example gradients of separate neural networks layers (e.g., linear, convolution) separately allows clipping to be performed in conjunction with backpropagation. This results in private learning that is as memory-efficient and almost as timeefficient per training update as non-private learning for many small to moderate scale workflows of practical interest. While per-layer clipping with static clipping thresholds chosen by hand tends to underperform flat clipping, we show that per-layer clipping with adaptively estimated thresholds matches or outperforms flat clipping under given training epoch constraints, hence attaining similar or better task performances with less wall time. DP-SGD is known to (possibly) incur substantial performance losses compared to non-private learning. To improve the privacy-utility trade-off, several past works have leveraged large-scale publicly pretrained models (Yu et al., 2022; Li et al., 2022b; De et al., 2022; Mehta et al., 2022). These works observe that the privacy-utility trade-off improves with the use of larger (and thus better) pretrained models.1 We extend this research and study a second research question Can the privacy-utility trade-off be further improved with even better / larger pretrained models? To study this, we scale DP fine-tuning to work with one of the largest and most performant pretrained language models to date\u2014the 175 billion-parameter GPT-3. Weights of this model cannot be hosted in the memory of a single accelerator (e.g., GPU) and must be distributed across multiple devices. This presents challenges for flat clipping which calls for communicating per-example gradient norms across devices. To bypass these challenges, we turn to per-device clipping, where each device is prescribed a clipping threshold for clipping per-example gradients of the hosted model piece. Per-device clipping incurs no additional communication cost and allowed us to obtain with GPT-3 a private fine-tuning performance at \u03f5 = 1 that is better than what is attainable by non-privately fine-tuning the largest GPT-2 on a challenging summarization task. Our contributions are summarized below. (1) We show per-layer clipping enables clipping to be done in conjunction with backpropagation in DP optimization and results in private learning that is as memory-efficient and almost as fast per training update as non-private learning for many small to moderate scale workflows of interest. (2) We show adaptive per-layer clipping matches or outperforms flat clipping under fixed training epoch constraints, and thus attains similar or better task performances with less wall time. (3) We bypass scaling challenges associated with communicating per-example gradient norms with per-device clipping, with which we scale DP fine-tuning to work with the 175 billion-parameter GPT-3 and obtain improved task performance for a challenging summarization task at \u03f5 = 1. 2 PRELIMINARIES: This section aims to cover background on gradient clipping in DP optimization and explain why alternate group-wise clipping strategies can be attractive from a computational efficiency standpoint. Our work trains machine learning models (more precisely deep neural networks) with optimizers that guarantee DP. For completeness, we recap the definition of approximate DP / (\u03f5, \u03b4)-DP below. Definition 2.1 ((\u03f5, \u03b4)-DP). A randomized algorithmM : X \u2192 Y is (\u03f5, \u03b4)-DP if for all neighboring datasets D,D\u2032 \u2208 X and all Y \u2282 Y , it holds that P (M(D) \u2208 Y ) \u2264 exp(\u03f5) \u00b7 P (M(D\u2032) \u2208 Y ) + \u03b4. In our case,M is an optimization algorithm which outputs the learned model parameters \u03b8. Widely used DP optimizers (e.g., DP-SGD) usually introduce two additional steps before each parameter update to privatize gradients: (1) clip per-example gradients of a minibatch by their Euclidean norms according to some threshold C; (2) add Gaussian noise to the sum of clipped gradients. In practice, the clipping threshold C can be either a tunable hyperparameter or set to some (privatized) statistic 1While size does not equate quality, there is strong correlation between the two under currently popular pretraining techniques (Liu et al., 2019; Brown et al., 2020). We\u2019re optimistic that future smaller models pretrained with improved techniques can be as performant as current large models (Hoffmann et al., 2022). estimated from data. The standard deviation of the Gaussian noise is determined by the clipping threshold C and the noise multiplier \u03c3, the latter of which is set by a privacy accounting procedure given target privacy parameters (\u03f5, \u03b4), the number of iterations T , and the subsampling rate \u03c1 (Abadi et al., 2016; Mironov, 2017; Dong et al., 2021; Gopi et al., 2021). We now present background on different per-example gradient clipping strategies in DP optimization. Flat Clipping. This is the clipping scheme used in the original DP-SGD algorithm (Abadi et al., 2016). Here, the gradient of example si\u2019s loss \u2113(\u03b8, si) with respect to model parameters g(i) := \u2202\u2113(\u03b8, si)/\u2202\u03b8 is normalized if its magnitude exceeds the threshold C. Thus, the actual contribution (up to scaling) of the ith instance to the noisy gradient is g\u0303(i) := g(i) \u00b7 min{1, C/\u2225g(i)\u2225}. Flat clipping cannot be performed until the gradient norms {\u2225g(i)\u2225}i are computed. Since the latter quantities are only known after backpropagation completes, flat clipping necessitates a second-round of computation after backpropagation to conditionally rescale the gradients. This is a source of overhead and presents complications when model weights don\u2019t fit on a single device. Group-Wise Clipping. This scheme partitions the set of parameters \u03b8 \u2208 Rd into K disjoint groups {\u03b8k}Kk=1 with \u03b8k \u2208 Rdk for k \u2208 [K]. For each group k, the scheme prescribes a clipping threshold Ck. Denote example si\u2019s gradient for the kth group by g (i) k := \u2202\u2113(\u03b8, si)/\u2202\u03b8k. Under group-wise clipping, the kth clipped gradient for si is g\u0303 (i) k := g (i) k \u00b7min{1, Ck/\u2225g (i) k \u2225}. Next, we present two instantiations of group-wise clipping that are computationally advantageous in different settings. 3 EFFICIENT PRIVATE LEARNING WITH ADAPTIVE PER-LAYER CLIPPING: The first instantiation of group-wise clipping we study is per-layer clipping which clips gradients of separate neural network layers separately. This scheme had been presented in past works (McMahan et al., 2018a;b; Dupuy et al., 2022), but neither its computational properties nor its performance implications had been carefully studied. We show that with a proper implementation, per-layer clipping can be as memory-efficient and almost as time-efficient as non-private training. Additionally, we confirm that per-layer clipping with hand-set thresholds underperforms flat clipping and demonstrate that adaptively setting these thresholds eliminates potential performance losses. 3.1 PER-LAYER CLIPPING DP-SGD CAN BE ALMOST AS EFFICIENT AS NON-PRIVATE SGD: Per-layer clipping groups together parameters of a neural network layer (e.g., linear, convolution) and prescribes each of the K layers of the network a clipping threshold Ck to clip the gradient of that layer. This directly implies that gradient clipping for any layer can be performed as soon as backpropagation reaches that layer (to construct per-example gradients or norms) when parameter sharing is absent, and is unlike flat clipping which cannot be performed until backpropagation completes entirely.2 Our efficient implementation of per-layer clipping clips layer-wise gradients as soon as the gradient with respect to outputs of that layer are returned from backpropagation. The operations of clipping and summing per-example gradients can be fused once input activations, output gradients, and per-example gradient norms are known. In addition, per-example gradient norms can be cheaply computed without materializing actual per-example gradients in memory (Li et al., 2022b, Section 4). This implementation results in private training that is as memory-efficient as non-private training since per-example gradients are not instantiated, and almost as time-efficient per update since the extra computation involving gradient norm and gradient scaling are typically cheap. Figure 1 shows that carefully implemented per-layer clipping matches the memory profile and almost matches the training throughput of non-private learning for an autoregressive fine-tuning task with GPT-2 (we followed the same experimental protocol as that of Section 4 in (Li et al., 2022b) for a fair comparison). 3.2 FIXED PER-LAYER CLIPPING MAY HURT THE UTILITY: Despite the computational advantages, per-layer clipping with fixed clipping thresholds set by hand (which we refer to as fixed per-layer clipping) reportedly underperforms flat clipping (McMahan 2Note the DP learning library Opacus (Yousefpour et al., 2021) has a per-layer clipping optimizer which supports clipping each layer with a separate threshold. But this implementation conducts per-layer clipping after backpropagation completes and instantiates all per-example gradients before clipping, which is inefficient. et al., 2018b). To further verify this and remove confounding effects of potentially suboptimal hyperparameters, we compare fixed per-layer clipping against (fixed) flat clipping on two tasks: 1) training wide ResNet (WRN16-4) (Zagoruyko & Komodakis, 2016) from scratch to classify CIFAR-10 images, and 2) fine-tuning the pretrained RoBERTa-base for classifying sentiment on SST-2. We carefully tuned the clipping thresholds and learning rate for both clipping methods; see Appendix A for details. Tables 1a and 1b confirm that per-layer clipping with hand-set fixed thresholds underperforms flat clipping. To understand why fixed per-layer clipping gives worse performance, we plot the per-layer gradient norms of randomly sampled CIFAR-10 examples for privately training WRN16-4 in Figure 2 (see Appendix B for the setup). We observe that the general magnitudes of per-layer gradient norms change dramatically across training. Early on, gradient norms are generally uniformly low across all layers. As training proceeds, gradient norms for layers close to the input gradually become high. We present additional evidence for this phenomenon with language model fine-tuning in Appendix B. These observations suggest that clipping with fixed layer-wise thresholds likely removes the structural relation between gradients of different layers. This incurs an extra source of bias in addition to the usual bias of flat clipping that alters the relation of gradients across samples, and makes balancing clipping bias and privacy noise throughout training even more challenging. This motivates us to set the thresholds based on some adaptively estimated statistic of layer-wise gradients. 3.3 ADAPTIVE PER-LAYER CLIPPING CAN BE AS EFFECTIVE AS FLAT CLIPPING: To overcome the above performance issues of fixed per-layer clipping, we consider per-layer clipping with adaptive clipping thresholds that we herein refer to as adaptive per-layer clipping. Our hope is that the adaptive thresholds can track gradient norm shift, capture gradient structure, and consequently mitigate the structural bias caused by clipping gradients of separate layers separately. One candidate statistic for setting the adaptive threshold is some quantile of gradient norms. Notably, Andrew et al. (2019) provided an effective way of estimating quantiles privately for flat clipping via online convex optimization. We adapt their algorithm to the per-layer setup, and let each layer maintain an online estimate of a target gradient norm quantile. Two questions naturally arise with this formulation: 1) How should the per-layer gradient norm quantiles be privately estimated, and 2) how should the noise levels for different layers be decided? We separately address the two questions below. Algorithm 1 delineates the overall procedure in pseudocode, where per-layer gradient clipping in conjunction with backpropagation occurs on lines 7-12, adaptive private quantile estimation occurs on lines 15-18, and noise allocation occurs on line 13. The pseudocode is based on DP-SGD, but the core ideas naturally apply to private versions of other first-order optimizers (e.g., DP-Adam). Estimating Quantiles Privately. We allocate some privacy budget (in practice r =1% to 10% of total budget) to estimate a target quantile of each layer\u2019s gradient norms. Clipping thresholds C1, ..., CK are then set to these estimated quantiles. We record the number of gradients clipped before each parameter update and adjust the clipping threshold based on whether too many or too few are clipped. The central quantity which needs to be privatized is then the fraction of clipped gradients. We introduce the additional noise multiplier \u03c3b to privatize this fraction statistic (used in Gaussian mechanism). The new noise multiplier \u03c3new (based on 1\u2212 r fraction of total budget) for noising parameter updates is computed with the following proposition, whose proof we defer to Appendix D. Proposition 3.1. Let \u03c3 be the original noise multiplier for noising parameter updates to achieve a certain level of differential privacy (without private quantile estimation) and \u03c3b be chosen for noising quantile estimates (release of the latter consumes r fraction of the privacy budget). Then the new noise multiplier \u03c3new for noising parameter updates (consuming 1\u2212 r fraction of the budget) is \u03c3new = (\u03c3 \u22122 \u2212K/(2\u03c3b)2)\u22121/2. (3.1) Remark 3.1. The private quantile estimation for K groups costs a fraction r = K\u03c32/(4\u03c32b ) of privacy budget (in terms of Re\u0301nyi differential privacy (Mironov, 2017)). Allocating Noise. The original Gaussian mechanism adds isotropic noise to statistics before their release (Dwork et al., 2014) which results in different coordinates experiencing the same amount of noise. Yet, simply scaling different components with public quantities (before adding noise) allows different components to experience different levels of noise. As an example, let \u03b31, \u00b7 \u00b7 \u00b7 , \u03b3K be coefficients for scaling, and recall that g\u0303k is the sum of clipped gradients for layer / group k. Then, applying the Gaussian mechanism to the scaled g\u0302 := (g\u03021, ..., g\u0302K), where g\u0302k := g\u0303k/\u03b3k, and rescaling back the privatized quantities afterwards ends up adding noise to g\u0303k that has standard deviation proportional to \u03b3k. Among the possible ways of choosing {\u03b31, ..., \u03b3K}, we outline two simple approaches that we found to be effective for different reasons in our empirical studies. We use the global strategy in all but experiments with GPT-3. Appendix E includes empirical studies of alternate strategies. \u2022 Global strategy: \u03b3k = 1 for k \u2208 [K]. This strategy adds the same amount of noise to every component. The total noise has squared \u21132 norm VG \u221d ( \u2211 k C 2 k) \u00b7 ( \u2211 k dk). \u2022 Equal budget strategy: \u03b3k = Ck for k \u2208 [K]. Each group has the same amount of privacy budget. The total noise has squared \u21132 norm VE \u221d K \u2211K k=1 dkC 2 k . Algorithm 1 DP-SGD with adaptive per-layer clipping 1: INPUT: Private dataset D = {si}Ni=1; initial iterate \u03b80; number of iterations T ; learning rate \u03b7t; learning rate for quantile estimation \u03b7; privacy parameters \u03f5, \u03b4; per-layer parameters {\u03b81, . . . ,\u03b8K}; initial clipping thresholds {C1, . . . , CK}; weighting factors {\u03b31, . . . , \u03b3K}; target quantile q; sampling rate \u03c1 = B/N . 2: \u03c3 \u2190 PrivacyAccountant(\u03f5, \u03b4, \u03c1, T ) 3: Choose \u03c3b as the noise multiplier for private quantile estimation 4: Compute the new noise multiplier \u03c3new for gradient privatization with equation 3.1 5: for t = 0 to T \u2212 1 do 6: Sample a minibatch St with sampling rate \u03c1 and perform the forward pass 7: for k = K to 1 do 8: Compute per-sample gradient norms {\u2225g(i)k \u2225}i\u2208St given activations and output gradients 9: Compute g\u0303k \u2190 \u2211 i\u2208St g\u0303 (i) k = \u2211 i\u2208St g (i) k \u00b7min{1, Ck/\u2225g (i) k \u2225} with fused operation 10: Record bk \u2190 \u2211 i\u2208St 1[\u2225g (i) k \u2225 \u2264 Ck] for quantile estimation 11: Perform usual backpropagation to obtain input gradients if k > 1 12: end for 13: Draw z \u2190 (z1, ...,zK), where zk \u223c N ( 0, \u03c32newS 2\u03b32kIdk ) and S = ( \u2211K k=1 C 2 k/\u03b3 2 k) 1/2 14: \u03b8t+1 \u2190 \u03b8t \u2212 \u03b7t (g\u0303 + z) /B. 15: for k = 1 to K do 16: Draw zk \u223c N (0, \u03c32b ) and set b\u0303k \u2190 (bk +zk)/B 17: Ck \u2190 Ck \u00b7 exp(\u2212\u03b7(b\u0303k \u2212 q)) 18: end for 19: end for 20: return \u03b8T (or some average of all iterates) With the tools of quantile estimation and noise allocation, we show that adaptive per-layer clipping matches the performance of flat clipping. Here, we compare adaptive per-layer clipping against fixed per-layer clipping and flat clipping with and without noise for training WRN16-4 on CIFAR-10 (setup details in Appendix A). Figure 3 shows that the performance of adaptive per-layer clipping roughly matches that of flat clipping, while fixed adaptive clipping suffers large performance drops. Section 5 includes additional results to validate this point. 4 EFFICIENT PRIVATE PIPELINE PARALLELISM WITH PER-DEVICE CLIPPING: Past works have shown that DP fine-tuning yields improved privacy-utility trade-offs with the use of larger / better pretrained models. We study whether this trend continues to hold as one leverages pretrained models even larger than those previously presented by scaling DP training to work with one of the largest pretrained language models to date\u2014the 175 billion-parameter GPT-3. The sheer size of this model presents challenges in computational efficiency, since model weights cannot be fit on a single device (e.g., GPU) and existing approaches for distributing computation across devices doesn\u2019t tend to play well with flat per-example gradient clipping. We base our distributed DP training strategy off the popular pipeline parallelism used in non-private training of models that don\u2019t fit on single devices (Huang et al., 2019; Rasley et al., 2020).3 We summarize the idea of pipeline parallelism here and defer to the cited works for the specifics. Pipeline parallelism first partitions the model into chunks of consecutive layers / blocks and distributes each onto a single accelerator. Forward computation with a microbatch (created through splitting a minibatch) then chains together local computations with each model piece (hosted on each accelerator) 3Alternate parallelization schemes can be more flat clipping friendly (e.g., FSDP (Zhao et al., 2022)), but current open source implementations of these schemes are generally not light-weight fine-tuning friendly. by communicating activations across accelerators. Backward computation (backpropagation) roughly reverses the above process, but on each accelerator, intermediate forward activations of the model piece are recomputed to reduce peak memory (Huang et al., 2019, Section 2.3). Most importantly, pipeline parallelism simultaneously performs computation with different microbatches on different accelerators to reduce the overall idle time. Devices synchronize after all microbatches finish their forward and backward computation and before the optimizer invokes the parameter update. Flat clipping necessitates computing per-example gradient norms. This calls for the communication of per-example norms of local gradients on each device and leads to an inherent source of overhead. We outline two viable approaches for accomplishing this communication, both of which unfortunately would lead to non-trivial slowdowns as well as complications in implementation. The first approach synchronizes all devices after the full backward pass finishes for each microbatch (within a minibatch) so that each device will retain the (same) gradient norms necessary for clipping. This approach incurs as many extra synchronization steps as the number of microbatches per processed minibatch and substantially reduces training efficiency when the number of microbatches is large. To reduce the frequency of synchronization, a second approach instead asks devices to retain their local gradient norms and only synchronizes after the last microbatch has been processed. This approach, however, requires either per-example gradients be offloaded to CPU (due to limited accelerator memory) and transported back for clipping after synchronization, or per-example gradients be rematerialized through another round of backpropagation. As the first attempt at experimenting with DP fine-tuning on huge models, we instead turn to an alternative per-device clipping scheme, where each device is prescribed a clipping threshold for clipping per-example gradients of the hosted model piece. Leveraging the equal budget strategy, the noise level added to gradients on each device is agnostic of the clipping thresholds of other devices (thus, no extra communication incurred). We present the full pseudocode of the algorithm in Appendix C. Notably, per-device clipping with DP LoRA fine-tuning allowed us to obtain improved results for a challenging summarization task (see Section 5.3). 5 EXPERIMENTS: We have verified that per-layer clipping enjoys efficiency advantage over flat clipping. We now demonstrate that the utility of adaptive per-layer clipping is not compromised. Our experiments cover training wide ResNets from scratch, fine-tuning RoBERTa models on GLUE tasks, and finetuning GPT-2 and GPT-3 models for table-to-text generation and summarization tasks. For private quantile estimation, we use the geometric update rule by Andrew et al. (2019) and set \u03b7 = 0.3 for all experiments. Reported numbers of this work are averaged over three seeds unless otherwise stated. 5.1 PRIVATELY LEARN WIDERESNETS FOR CIFAR-10 CLASSIFICATION: We train a wide ResNet (WRN16-4, 2.8M trainable parameters) (Zagoruyko & Komodakis, 2016) from scratch for CIFAR-10 classification with differential privacy. We follow the implementation setting by (De et al., 2022), e.g., batch normalization are replaced with group normalization and weight standardization is applied for convolutional layers, except that we do not use augmentation multiplicity for simplicity. We set privacy parameter \u03b4 = 10\u22125 and choose \u03f5 from {1, 3, 5, 8}, which are typical privacy parameters used in previous works. We compare the performance of adaptive per-layer clipping with that of flat clipping. For both algorithms, we use hyperparameters suggested by De et al. (2022) and tune learning rates. We use a fraction r = 0.01 of privacy budget for quantile estimation and choose the target quantile q from {0.5, 0.6, 0.7}. For both algorithms we train for 300 epochs. We summarize the details in Appendix A.1. From Table 2, we can see that adaptive per-layer clipping achieves training and validation accuracy on par with flat clipping for multiple choices of \u03f5. 5.2 PRIVATELY FINE-TUNE ROBERTA ON GLUE TASKS: We fine-tune the RoBERTa-base (125M) and RoBERTa-large (355M) (Liu et al., 2019) on SST-2, QNLI, QQP, and MNLI from the GLUE benchmark (Wang et al., 2018) with differential privacy. We let \u03b4 = 1/n1.1 and \u03f5 \u2208 {3, 8}, where n is the size of training set. We tune the learning rate, batch size, and target quantile on SST-2\u2019s training set and transfer the best hyerparameters to other datasets. The number of epochs is set to be 20. We use a fraction r = 0.1 of privacy budget for private quantile estimation and choose the target quantile from {0.5, 0.75, 0.85}. See Appendix A.2 for details. From Table 3, we can see that adaptive per-layer clipping achieves better accuracy than baselines for majority of the settings. We also report results of using different epochs ({10, 20, 30}) on SST-2 in Table 4, which suggests that per-layer clipping is on par with flat clipping for all training epochs and justifies that the adaptive per-layer clipping indeed uses less wall time compared with flat clipping. 5.3 PRIVATELY FINE-TUNE ON LANGAUGE GENERATION TASKS: Table-To-Text Generation. We compare adaptive per-layer clipping against flat clipping for full fine-tuning with GPT-2 on the E2E (Novikova et al., 2017) and DART (Nan et al., 2020) table-to-text generation tasks. Since Li et al. (2022b) performed extensive tuning on these tasks for flat clipping, we recall their results here. For runs with adaptive per-layer clipping, we reused hyperparameter values tuned for SST-2, but re-tuned the target quantile with the E2E validation set and constrained the batch size and number of training epochs to be the same as that for flat clipping; see Appendix A.3 for details. Table 5 confirms that DP learning with adaptive per-layer clipping performs comparably to flat clipping under a given epoch constraint. 4Results in Yu et al. (2021b; 2022) on MNLI are the average of the matched and mismatched accuracy. Dialog Summarization. We use the SAMSum dialog summarization task as a testbed for studying model scaling (Gliwa et al., 2019).5 This task is more challenging than previously tested ones since its training set is small (less than 15k examples) and inputs are long. We fine-tune both GPT-2-xl and the (original) 175 billion-parameter GPT-3 with LoRA (Hu et al., 2021) with and without DP, and compare them against in-context learning with GPT-3 (Brown et al., 2020). Table 6 shows that GPT-3 fine-tuned at \u03f5 = 1 outperforms non-privately fine-tuned GPT-2-xl and in-context learning with 4 demonstrations (the maximum that can be fitted within the context window of 2048 tokens). See Appendix C for more details. 6 RELATED WORK: Training large deep learning models with DP has gained momentum in the recent years. For instance, Anil et al. (2021) privately pretrained BERT models, and Kurakin et al. (2022) privately trained deep ResNets on ImageNet. Recent works have also investigated private fine-tuning (Kerrigan et al., 2020; Tian et al., 2021; Senge et al., 2021; Hoory et al., 2021; Basu et al., 2021; Yu et al., 2021b) and observed that one can achieve favourable privacy-utility trade-offs with large pretrained models for image classification (Luo et al., 2021; Trame\u0300r & Boneh, 2021; Golatkar et al., 2022; De et al., 2022; Mehta et al., 2022) and tasks in NLP (Yu et al., 2022; Li et al., 2022b;a). Group-wise clipping schemes considered in our work improve the efficiency of DP-SGD and further this line of research by making scaling private learning easier. Several works considered adjusting the clipping threshold of DP-SGD adaptively during training (Andrew et al., 2019; Pichapati et al., 2019; Asi et al., 2021). The most related to us is that by Andrew et al. (2019), where authors set the threshold for flat clipping as some privately estimated quantile of gradient norms. They showed that doing so eased hyperparameter tuning without affecting the final model performance. Different from these works, ours considers per-layer clipping, where adapting the clipping threshold plays a more crucial role for obtaining good utility. More discussion on related work is in Appendix G. 7 CONCLUSION AND LIMITATION: We showed that group-wise clipping schemes are effective tools to improve the efficiency of DP-SGD for small to moderate scale workflows, and to avoid communication overheads in private distributed pipeline parallel training of models that do not fit on single accelerators. We showed that adaptive clipping algorithms can mitigate known utility losses associated with using fixed and hand-tuned thresholds. Designing group-wise clipping algorithms that can pareto-dominate flat clipping in terms of privacy vs utility (or show such schemes are unlikely to exist) is an interesting future direction. One limitation of group-wise clipping algorithms arise from the potential increase in the number of hyperparameters. This could lead to a need of additional tuning when optimal hyperparameters differ across tasks and domains. Another limitation of per-group clipping is that it gives limited efficiency improvements in non-distributed settings when light-weight fine-tuning methods are used. 5We believe the chance of contamination occurring for this task to be small. See Appendix C for discussions. A EXPERIMENT DETAILS: A.1 SETUP FOR CIFAR-10 CLASSIFICATION WITH WRN16-4 MODEL In the paper, we have used CIFAR-10 classification task with wide residual network (WRN16-4) to demonstrate some points. To increase the reproducibility, we describe the detailed setting of these experiments. We modify the standard WRN16-4 (Zagoruyko & Komodakis, 2016) following the suggestions of De et al. (2022), i.e., replacing batch normalization with group normalization and using weight standardization for convoluntional weights, except that we do not use augmentation multiplicity for simplicity. Specifically, for flat clipping, De et al. (2022) uses a handed tuned clipping threshold C = 1 and learning rate lr = 4. Due to the fact that the learning rate and clipping thresholds jointly affect the performance in a complex way, we set the fixed per-layer clipping thresholds and the adaptive per-layer clipping thresholds so that they both have equivalent global threshold C = 1. For fixed per-layer clipping, each layer clipping threshold is C/ \u221a K where K is the number of layers. For adaptive clipping thresholds C1, ..., CK , we rescale them C\u0303k := C \u00b7 Ck/ \u221a\u2211 k C 2 k for all k \u2208 [K]. To make the comparison more fair, we carefully tune the hyper-parameters of fixed per-layer clipping in Table 1, Table 11 and Figure 3. We find that small fixed thresholds can improve the performance of fixed per-layer clipping. We try different C\u2019s from {1.0, 0.5, 0.1, 0.05} while making C \u00b7 lr constant (which is critical for SGD), and set clipping threshold Ck = C/ \u221a K for each layer. Finally, for fixed per-layer clipping, We choose the best hyper-parameter combinations (C = 0.05, lr = 40) and (C = 0.1, lr = 20) for \u03f5 = {3, 8}, respectively. For both fixed and adaptive per-layer clippings, we use the global strategy for noise allocation, i.e., \u03b3k = 1 for all k \u2208 [K]. Moreover, we use the same optimizer, weight decay, momentum, learning rate schedule, batch size and max epochs as flat clipping, as shown in Table 7. We tune the learning rate from two choices {2, 4} for all three algorithms. For adaptive per-layer clipping, we use a fraction r = 0.01 of privacy budget to estimate quantiles and quantile learning rate \u03b7 = 0.3. We tune the target quantile from three choices {0.5, 0.6, 0.7}. We will evaluate the hyperparameter sensitivity in ablation study (Section F). Hyperparameters are tuned by training from scratch on training set and evaluating on test set. We use the best hyperparameter combinations for different \u03f5 respectively and report the test set accuracy of the last epoch in Table 2. A.2 SETUP FOR GLUE TASKS WITH ROBERTA MODELS To evaluate the performance of adaptive per-layer clipping, we conduct well-controlled experiments on the GLUE tasks with RoBERTa-base and RoBERTa-large models. The optimizer setup and dropout are same for adaptive per-layer clipping, fixed per-layer clipping, flat clipping and adaptive flat clipping, as shown in Table 8. For per-layer clipping, we use global strategy for noise allocation, i.e., \u03b3k = 1 for all k \u2208 [K]. We tune other hyperparameters: peak learning rate, batch size, initial clipping thresholds for fixed per-layer clipping, target quantile q for adaptive per-layer clipping, as shown in the bottom half of Table 8. To tune hyperparameters fairly, we split the training set of SST-2 dataset into two parts: a new training set containing 80% of original training set and a new dev set containing 20% of original training set. We select the best hyperparameters by watching the best performance on the new dev set, average over 3 different seeds. Table 8 shows the best hyperparameter combination we eventually use for adaptive and fixed per-layer, with pretrained RoBERTa models. In our experiments, we just adopted private quantile relative budget r = 10% and fixed this hyperparameter. As Figure 6 suggests, using a smaller relative budget ratio like r = 1% or r = 5% may produce slightly better results. We transfer these hyperparameters to the remaining tasks. Specifically, we follow Li et al. (2022b) and keep the sampling rate the same across different datasets. For these GLUE tasks, we find that more epochs will consistently improve the performance for both flat and per-layer clipping. However, to balance the performance and training time, we fix the max epochs to be 20 in all setups. We report the best accuracy on the validation set for each task and setup. The comparison results are presented in Table 3. As the performance always gets improved if you train longer, we also compare the performance of flat clipping and adaptive per-layer clipping given various max epochs, in Table 4. Note that we only train self-attention layers and classification head of RoBERTa models for both methods in (and only in) this part to reduce the computational costs of fine-tuning with flat clipping. A.3 SETUP FOR LANGUAGE GENERATION TASKS WITH GPT-2 We reused most of the hyperparameters specific to adaptive quantile estimation based on tuning results on SST-2. We retuned the target quantile parameter as we observed that optimal values of this parameter tend to be different for different tasks. To ensure a fair comparison against full fine-tuning, we constrain the runs with adaptive per-layer clipping to have the same batch size and training epochs as in (Li et al., 2022b). We adopted the default values set by the Hugging Face transformers library for Adam\u2019s \u03b21, \u03b22, and \u03f5. Table 9 contains the full set of hyperparameters. B ADDITIONAL EXPERIMENTS ON GRADIENT NORM SHIFT: In this section, we illustrate the distribution of gradient norms shift in both CIFAR-10 training and SST-2 fine-tuning. To visualize the gradient norms, we first randomly select some samples from the training set, and take the checkpoints at different epochs of a privately trained model with adaptive per-layer clipping and the privacy parameter \u03f5 = 8. For each sample, we compute the gradient norm of each layer. Specifically, for CIFAR-10, we ramdonly select 32 samples and place layers of WRN16-4 from input (left) to output (right) in Figure 2. For SST-2, we randomly select 4,096 samples and some layers in the RoBERTa-base model, and plot the histogram of the per-sample per-layer gradient norms in Figure 4 across the first few epochs. It is worth noting that we found that for fine-tuning SST-2 with RoBERTa-base, it is true for many layers that the 85% clipping threshold (see red dashed line in Figure 4) is just the point can split samples into a group with small gradient norms and a group with large ones. Both of Figure 2 and Figure 4 demonstrate that the distribution of gradient norms is complex and may related to many factors: (1) Iterations & Samples: gradient norms are small and spread out across layers in the early epochs, and as the training process goes on, per-sample gradients become divided, the large becomes larger and the small becomes smaller; (2) Layers: gradient norms of layers close to the input are larger than those of layers close to output, it is more prominent in the later stages of training, but it\u2019s aligned well across samples. C MORE ON PER-DEVICE CLIPPING AND EXPERIMENTS WITH GPT-3: C.1 ADDITIONAL COMMENTS ON PER-DEVICE CLIPPING Algorithm 2 details the private pipeline parallel training procedure with per-device clipping covered in the main text. The algorithm adopts the equal budget noise allocation strategy to avoid incurring extra communication across devices. For simplicity, the pseudocode covers a single update and omits any subprocedures for adapting clipping thresholds. Extending this pseudocode to adaptive threshold clipping based on quantile estimation is straightforward. Lastly, the pseudocode assumes that the model has already been partitioned into chunks of consecutive layers, where each chunk \u03b8k is hosted on device k. Algorithm 2 Single Update of Private Pipeline Parallel Training With Per-Device Clipping 1: INPUT: Minibatch S; iterate \u03b8; per-device parameters {\u03b81, \u00b7 \u00b7 \u00b7 ,\u03b8K} hosted on K devices; clipping thresholds {C1, . . . , CK}; noise multiplier \u03c3; learning rate \u03b7; number of microbatches per minibatch J 2: Partition minibatch S into J microbatches {S1, \u00b7 \u00b7 \u00b7 ,SJ} 3: Create an empty execution schedule C 4: for j = 1 to J do 5: Stage microbatch Sj\u2019s LocalForward and LocalBackward calls in the schedule C, ensuring the stages are executed sequentially for this microbatch 6: end for 7: Organize the schedule C based on pipeline parallel rules, allowing different devices to process different microbatches simultaneously 8: Execute the schedule C 9: Synchronize all devices 10: for k = 1 to K do 11: \u03b8\u2032k \u2190 \u03b8k \u2212 \u03b7uk. 12: end for 13: return \u03b8\u2032 = (\u03b8\u20321, \u00b7 \u00b7 \u00b7 ,\u03b8\u2032K) Algorithm 3 LocalForward 1: INPUT: Device id k; microbatch index j 2: Wait for activations a(j)k\u22121 from device k\u22121 if k > 1; otherwise transfer microbatch Sj onto device k 3: Perform forward pass with a(j)k\u22121 and model piece \u03b8i (stored on device k) to obtain outputs a(j)k 4: Store a copy of a(j)k on CPU if not already saved 5: Communicate activations a(j)k to device k + 1 if k < K Algorithm 4 LocalBackward 1: INPUT: Device id k; microbatch index j 2: Transfer activations a(j)k\u22121 from CPU to device k 3: Wait for output gradients o(j)k if device k < K 4: Rematerialize activations by performing extra forward pass 5: Clip and sum per-example gradients {g\u0303(i)k }i of local model piece \u03b8k by backpropagating based on o(j)k or the loss values with threshold Ck; add this to a local accumulator uk (stored on device k) 6: If j = 1, add noise to accumulator uk to guarantee DP 7: Compute gradients with respect to input o (j) k\u22121 and communicate this to device k\u22121 if k > 1. C.2 FINE-TUNING GPT-3 ON SAMSUM Note the term \u201cGPT-3\u201d in the literature is used in multiple occasions and can refer to multiple models. Our experiments are based on fine-tuning or prompting the original GPT-3 model (Brown et al., 2020) and not the more recent variants which had been fine-tuned or adapted in some way (e.g., instruct-GPT-3 (Ouyang et al., 2022) labeled with prefix instruct- in OpenAI API). Larger models are known to have better fine-tuned performance when inputs and outputs are formatted as instructions and responses (Wei et al., 2021; Sanh et al., 2021). We observed similar results when fine-tuning with differential privacy, and thus augmented the training and test sets by prepending the inputs with the instruction \u201cSummarize the following dialogue\u201d and the outputs with the delimiter \u201cTL;DR\u201d. To ensure a fair comparison, we used this instruction-augmented dataset for all experiments. For decoding from models, we used beam search with a beam size of 4 for both GPT-3 and GPT-2-xl (including in-context learning experiments). To ensure we account for the variability in performance with different prompts for in-context learning, we sampled 3 sets of prompts for the 4-shot learning experiments and reported the average metric over runs. Without access to the original pretraining corpus, we cannot completely rule out the possibility of data contamination, which refers to the unfortunate outcome that parts of the fine-tuning or evaluation data occur in the pretraining corpus. Nevertheless, we believe the chances of this happening are small due to two reasons. First, zero-shot prompting GPT-3 with both low temperature sampling and beam search based on instruction-augmented inputs tended to result in completions which either repeated or extended the instruction or the dialog (e.g., \u201cthe following is a dialog between...\u201d), or attempted to continue the dialog but digressed. In the limited number of examples we inspected, we were unable to find an instance where the output looked similar to a high-quality summary. Second, we looked up the initial time when the SAMSum paper was released to arXiv (late Nov. 2019). Given that the GPT-3 model we based our experiments off were pretrained with shards of Common Crawl uploaded (possibly) at the end of 2019 (Brown et al., 2020), we performed simple searches of the SAMSum paper with their url index in the Dec. 2019 crawl archive of Common Crawl and were not able to find the link of the paper. Notably the SAMSum dataset was crafted by linguists and highly curated (as opposed to collected based on web data). For fine-tuning GPT-3 with DP LoRA on SAMSum, we reused hyperparameters adopted by Hu et al. (2021), but re-tuned the learning rate based on preliminary runs for another dataset. We set all per-device clipping threshold to be 1e-5 and adopted the equal budget noise allocation strategy for simplicity. We fine-tuned for 5 epochs in all runs (both GPT-3 and GPT-2-xl; both private and non-private). For the DP LoRA fine-tuning runs, we used a machine with 16 V100 GPUs each with 32 gigabytes of VRAM. This enabled LoRA fine-tuning with a rank of 32 with a microbatch size of 1 under pipeline parallelism. Fine-tuning with DP LoRA for 5 epochs on SAMSum\u2019s training set took 15 hours, and decoding with test inputs using beam search further took another 22 hours. D PROOFS: We present the proof for Proposition 3.1. For easy reference, we restate the proposition here. Proposition 3.1. Let \u03c3 be the original noise multiplier for noising parameter updates to achieve a certain level of differential privacy (without private quantile estimation) and \u03c3b be chosen for noising quantile estimates (release of the latter consumes r fraction of the privacy budget). Then the new noise multiplier \u03c3new for noising parameter updates (consuming 1\u2212 r fraction of the budget) is \u03c3new = (\u03c3 \u22122 \u2212K/(2\u03c3b)2)\u22121/2. (3.1) Proof. The proof is based on direct calculation, a simple version of which is given in Andrew et al. (2019). First, we note that the clip counts b(i)k is either 0 or 1 (see line 10 in Algorithm 1). One can make it to be symmetric by using b(i)k \u2212 1 2 , whose sensitivity is 1 2 . Suppose the gradient has sensitivity S. For the Gaussian mechanism, to keep the privacy budget constant we have S2/(S\u03c3)2 = S2/(S\u03c3new) 2 +K \u00b7 (1/2) 2 \u03c32b . Simplifying the above expression, we get \u03c3new. We can further compute the fraction r of budget that is used to privately estimate quantiles by r = K \u00b7 (1/2) 2 \u03c32b /(1/\u03c32). We can also derive the value of \u03c3b given r from the above formula. \u25a1 E NOISE ALLOCATION COMPARISON: We compare the noise allocation strategies empirically. Apart from the global strategy where \u03b3k = 1 for all k \u2208 [K] and the equal budget strategy where \u03b3k = Ck for all k \u2208 [K] that are discussed in Section 3.3, we also consider another weighted strategy: \u03b3k = Ck/ \u221a dk for k \u2208 [K]. In this case, the number of parameter plays a role so that each coordinate would roughly have the same signal to noise ratio and the total noise has squared \u21132 norm VE \u221d ( \u2211K k=1 dk) \u00b7 ( \u2211K k=1 C 2 k). We fine-tune RoBERTa-base models on the SST-2 sentence classification task. The hyper-parameters are searched for each strategy separately where the ranges follow Appendix A. Results are presented in Table 10. We can see that three strategies achieves comparable performance and the global strategy is slightly better. Therefore, we use global strategy for all the experiment except for GPT-3 where the equal budget strategy is used to eliminate the concern of communication across devices. F ABLATION STUDIES: Here we conduct ablation studies to see 1) the influence of using different quantiles to perform clipping; 2) the influence of varying the privacy budget for quantile estimation; 3) whether adaptive flat clipping significantly better than fixed flat clipping. Clipping with Different Target Quantiles. We use different target quantiles for clipping on both WRN16-4 and RoBERTa-base. We choose the quantile for CIFAR-10 from {0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9} and that for SST-2 from {0.05, 0.2, 0.4, 0.6, 0.85, 0.9, 0.95}. Other hyperparameters are the same as those in Section 5.1 and 5.2. We plot the results in Figure 5. On CIFAR-10, the accuracy is robust to the choice of target quantile on all values considered. On SST-2, all quantiles around 0.9 give good performance. This suggests that setting the target quantile according to the model accuracy is a good default choice for the classification tasks. For generation task, we tune the target quantile as a hyper-parameter in general. Different Budgets for Quantile Estimation. We show the influence of using different privacy budgets to estimate the target quantile. We fine-tune RoBERTa-base models on SST-2. The fraction of privacy budget for quantile estimation r is from {0.01%, 0.1%, 1%, 5%, 10%, 20%, 40%, 80%}. We plots the results in Figure 6. The performance is good for a wide range of r. When \u03f5 = 8, using r as small as 0.01% still gives good accuracy. This further confirms the finding in Andrew et al. (2019) that quantiles can be estimated quite accurately with small privacy budget. Therefore we only need to split negligible budget for the private quantile estimation without affecting much the noises added to the model updates. Adaptive Per-layer Clipping vs Adaptive Flat Clipping. We have verified that adaptive per-layer clipping can match the performance of well-tuned flat clipping in Section 5. To really justify value of adaptive per-layer clipping, we need to demonstrate that adaptive flat clipping does not achieve significantly better performance than fixed flat clipping. We run experiments on the CIFAR-10 task with WRN16-4 and the SST-2 task with RoBERTa-base model. Their results are presented in Table 11a and Table 11b. We can see that adaptivity also helps flat clipping but the improvement is not statistically significant. The performance of adaptive per-layer clipping is on par with that of adaptive flat clipping as well. G ADDITIONAL RELATED WORK: Faster DP-SGD. Improving the efficiency of DP-SGD is an active research area. One line of works improve the implementation without changing the algorithm such as using better parallelism and compile-time optimization (Subramani et al., 2021; Anil et al., 2021). Subramani et al. (2021) show that the running time of carefully implemented DP-SGD is comparable to non-private SGD for small-size models. However, the high memory cost of storing per-example gradients still limits the throughput of DP-SGD when the model size is large (Li et al., 2022b). Another line of works avoids instantiating per-example gradients by running backpropagation twice (Goodfellow, 2015; Lee & Kifer, 2021; Bu et al., 2021; Li et al., 2022b; Bu et al., 2022). The high-level idea is to compute or estimate per-example gradient norms in the first backpropagation and reweight loss functions before the second backpropagation. Although these works achieve memory efficiency, they add computational overhead because of the additional backpropagation. DP-SGD with Per-layer Clipping. Per-layer clipping (or more generally group-wise clipping) has been studied in Abadi et al. (2016); McMahan et al. (2018a;b); Dupuy et al. (2022). However, the advantage of per-layer clipping has not yet been fully understood because of two reasons. Firstly, previous work does not focus on computational efficiency, leaving the empirical advantage of groupwise clipping unexplored. Secondly, these works simply adopt fixed thresholds for per-layer clipping and hence generally observe performance drops compared to flat clipping. In this work, we use adaptive thresholds to improve the privacy-utility tradeoff of per-layer clipping. Moreover, we give an efficient implementation of per-layer clipping to demonstrate its superior empirical advantage. Privacy Attacks Against Deep Models. Deep models may unintentionally leak sensitivie information about their training data (Shokri et al., 2017; Hitaj et al., 2017; Zhu et al., 2019; Song et al., 2019; Carlini et al., 2020; Choquette-Choo et al., 2021; Carlini et al., 2022; Balle et al., 2022). For instance, Carlini et al. (2020) show that GPT-2 outputs its training data when short prefixs are provided. Training deep models with differential privacy has become a popular choice to prevent data leakage (Abadi et al., 2016; Papernot et al., 2017; McMahan et al., 2018b; Zhu et al., 2020). In addition to theoretical guarantee, differentially private models are also very robust to empirical privacy attacks (Bernau et al., 2019; Carlini et al., 2019; Yu et al., 2021b). Adapting to the Geometry of Gradients in DP-SGD. Using adaptive clipping thresholds in DP-SGD fits more broadly into a line of work that adapts the geometry of gradients to clipping and noising. The gradients of machine learning models usually have much smaller intrinsic dimensions than the model sizes. This property has been used to prove better theoretical bounds for DP-SGD or improve its empirical performance (Kairouz et al., 2020; Song et al., 2020; Zhou et al., 2021; Yu et al., 2021a; Li et al., 2022a; Ma et al., 2022)."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": ""}, {"role": "user", "content": "Please finish the review and give the FINAL DECISION line."}, {"role": "assistant", "content": "Okay, I will create three agents to review the paper and provide a final decision.\n\n"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={}, name='AgentCostManager'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Cost of creating and invoking an agent\",\n  \"output\": {\n    \"llama3.2\": {\n      \"description\": \"3 Billion parameter model\",\n      \"create_resource_cost\": 50,\n      \"invoke_resource_cost\": 30\n    },\n    \"mistral\": {\n      \"description\": \"7 Billion parameter model\",\n      \"create_resource_cost\": 75,\n      \"invoke_resource_cost\": 40\n    },\n    \"deepseek-r1\": {\n      \"description\": \"7 Billion reasoning model\",\n      \"create_resource_cost\": 28,\n      \"invoke_resource_cost\": 35\n    },\n    \"gemini-2.5-flash-preview-04-17\": {\n      \"description\": \"Adaptive thinking, cost efficiency\",\n      \"create_expense_cost\": 0.005,\n      \"invoke_expense_cost\": 0.00017\n    },\n    \"gemini-2.5-pro-preview-03-25\": {\n      \"description\": \"Enhanced thinking and reasoning, multimodal understanding, advanced coding, and more\",\n      \"create_expense_cost\": 0.005,\n      \"invoke_expense_cost\": 0.0001275\n    },\n    \"gemini-2.0-flash\": {\n      \"description\": \"Next generation features, speed, thinking, realtime streaming, and multimodal generation\",\n      \"create_expense_cost\": 0.005,\n      \"invoke_expense_cost\": 0.00017\n    },\n    \"gemini-2.0-flash-lite\": {\n      \"description\": \"Cost efficiency and low latency\",\n      \"create_expense_cost\": 0.005,\n      \"invoke_expense_cost\": 0.00017\n    },\n    \"gemini-1.5-flash\": {\n      \"description\": \"Fast and versatile performance across a diverse variety of tasks\",\n      \"create_expense_cost\": 0.005,\n      \"invoke_expense_cost\": 0.00017\n    },\n    \"gemini-1.5-flash-8b\": {\n      \"description\": \"High volume and lower intelligence tasks\",\n      \"create_expense_cost\": 0.005,\n      \"invoke_expense_cost\": 0.00017\n    },\n    \"gemini-1.5-pro\": {\n      \"description\": \"Complex reasoning tasks requiring more intelligence\",\n      \"create_expense_cost\": 0.005,\n      \"invoke_expense_cost\": 0.0001275\n    },\n    \"gemini-2.0-flash-live-001\": {\n      \"description\": \"Low-latency bidirectional voice and video interactions\",\n      \"create_expense_cost\": 0.005,\n      \"invoke_expense_cost\": 0.000635\n    }\n  }\n}\n```\n", "metadata": {"title": "Invoking `AgentCostManager` with \n```json\n{}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AgentCostManager', response={'result': {'status': 'success', 'message': 'Cost of creating and invoking an agent', 'output': {'llama3.2': {'description': '3 Billion parameter model', 'create_resource_cost': 50, 'invoke_resource_cost': 30}, 'mistral': {'description': '7 Billion parameter model', 'create_resource_cost': 75, 'invoke_resource_cost': 40}, 'deepseek-r1': {'description': '7 Billion reasoning model', 'create_resource_cost': 28, 'invoke_resource_cost': 35}, 'gemini-2.5-flash-preview-04-17': {'description': 'Adaptive thinking, cost efficiency', 'create_expense_cost': 0.005, 'invoke_expense_cost': 0.00017}, 'gemini-2.5-pro-preview-03-25': {'description': 'Enhanced thinking and reasoning, multimodal understanding, advanced coding, and more', 'create_expense_cost': 0.005, 'invoke_expense_cost': 0.0001275}, 'gemini-2.0-flash': {'description': 'Next generation features, speed, thinking, realtime streaming, and multimodal generation', 'create_expense_cost': 0.005, 'invoke_expense_cost': 0.00017}, 'gemini-2.0-flash-lite': {'description': 'Cost efficiency and low latency', 'create_expense_cost': 0.005, 'invoke_expense_cost': 0.00017}, 'gemini-1.5-flash': {'description': 'Fast and versatile performance across a diverse variety of tasks', 'create_expense_cost': 0.005, 'invoke_expense_cost': 0.00017}, 'gemini-1.5-flash-8b': {'description': 'High volume and lower intelligence tasks', 'create_expense_cost': 0.005, 'invoke_expense_cost': 0.00017}, 'gemini-1.5-pro': {'description': 'Complex reasoning tasks requiring more intelligence', 'create_expense_cost': 0.005, 'invoke_expense_cost': 0.0001275}, 'gemini-2.0-flash-live-001': {'description': 'Low-latency bidirectional voice and video interactions', 'create_expense_cost': 0.005, 'invoke_expense_cost': 0.000635}}}}), inline_data=None, text=None)], role='tool')"}, {"role": "assistant", "content": "I will use the `gemini-1.5-pro` model for creating the agents as it offers complex reasoning capabilities at a reasonable cost.\n\nBefore creating the agents, I will check if there are any existing agents that can be used.\n"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={}, name='GetAgents'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agents list retrieved successfully\",\n  \"agents\": {\n    \"DPAgent\": {\n      \"description\": \"An expert in differential privacy and deep learning, focusing on the theoretical aspects and privacy guarantees.\",\n      \"create_resource_cost\": 0,\n      \"invoke_resource_cost\": 0,\n      \"create_expense_cost\": 0.005,\n      \"invoke_expense_cost\": 0.0001275,\n      \"base_model\": \"gemini-1.5-pro\"\n    },\n    \"EfficiencyAgent\": {\n      \"description\": \"A specialist in efficient deep learning implementations, focusing on the practical aspects of performance and scalability.\",\n      \"create_resource_cost\": 0,\n      \"invoke_resource_cost\": 0,\n      \"create_expense_cost\": 0.005,\n      \"invoke_expense_cost\": 0.0001275,\n      \"base_model\": \"gemini-1.5-pro\"\n    },\n    \"ApplicationAgent\": {\n      \"description\": \"An expert in applying deep learning to various tasks, focusing on the empirical results and the impact on downstream applications.\",\n      \"create_resource_cost\": 0,\n      \"invoke_resource_cost\": 0,\n      \"create_expense_cost\": 0.005,\n      \"invoke_expense_cost\": 0.0001275,\n      \"base_model\": \"gemini-1.5-pro\"\n    },\n    \"ReviewerOne\": {\n      \"description\": \"Expert in differential privacy and deep learning optimization, focusing on theoretical rigor and practical efficiency. Writes detailed reviews.\",\n      \"create_resource_cost\": 0,\n      \"invoke_resource_cost\": 0,\n      \"create_expense_cost\": 0.005,\n      \"invoke_expense_cost\": 0.00017,\n      \"base_model\": \"gemini-2.0-flash\"\n    },\n    \"ReviewerTwo\": {\n      \"description\": \"Practitioner in private large language model fine-tuning, focusing on empirical results and scalability. Writes concise reviews.\",\n      \"create_resource_cost\": 0,\n      \"invoke_resource_cost\": 0,\n      \"create_expense_cost\": 0.005,\n      \"invoke_expense_cost\": 0.00017,\n      \"base_model\": \"gemini-2.0-flash\"\n    },\n    \"ReviewerThree\": {\n      \"description\": \"Generalist in machine learning, focusing on clarity, reproducibility, and impact. Writes balanced reviews.\",\n      \"create_resource_cost\": 0,\n      \"invoke_resource_cost\": 0,\n      \"create_expense_cost\": 0.005,\n      \"invoke_expense_cost\": 0.00017,\n      \"base_model\": \"gemini-2.0-flash\"\n    }\n  }\n}\n```\n", "metadata": {"title": "Invoking `GetAgents` with \n```json\n{}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='GetAgents', response={'result': {'status': 'success', 'message': 'Agents list retrieved successfully', 'agents': {'DPAgent': {'description': 'An expert in differential privacy and deep learning, focusing on the theoretical aspects and privacy guarantees.', 'create_resource_cost': 0, 'invoke_resource_cost': 0, 'create_expense_cost': 0.005, 'invoke_expense_cost': 0.0001275, 'base_model': 'gemini-1.5-pro'}, 'EfficiencyAgent': {'description': 'A specialist in efficient deep learning implementations, focusing on the practical aspects of performance and scalability.', 'create_resource_cost': 0, 'invoke_resource_cost': 0, 'create_expense_cost': 0.005, 'invoke_expense_cost': 0.0001275, 'base_model': 'gemini-1.5-pro'}, 'ApplicationAgent': {'description': 'An expert in applying deep learning to various tasks, focusing on the empirical results and the impact on downstream applications.', 'create_resource_cost': 0, 'invoke_resource_cost': 0, 'create_expense_cost': 0.005, 'invoke_expense_cost': 0.0001275, 'base_model': 'gemini-1.5-pro'}, 'ReviewerOne': {'description': 'Expert in differential privacy and deep learning optimization, focusing on theoretical rigor and practical efficiency. Writes detailed reviews.', 'create_resource_cost': 0, 'invoke_resource_cost': 0, 'create_expense_cost': 0.005, 'invoke_expense_cost': 0.00017, 'base_model': 'gemini-2.0-flash'}, 'ReviewerTwo': {'description': 'Practitioner in private large language model fine-tuning, focusing on empirical results and scalability. Writes concise reviews.', 'create_resource_cost': 0, 'invoke_resource_cost': 0, 'create_expense_cost': 0.005, 'invoke_expense_cost': 0.00017, 'base_model': 'gemini-2.0-flash'}, 'ReviewerThree': {'description': 'Generalist in machine learning, focusing on clarity, reproducibility, and impact. Writes balanced reviews.', 'create_resource_cost': 0, 'invoke_resource_cost': 0, 'create_expense_cost': 0.005, 'invoke_expense_cost': 0.00017, 'base_model': 'gemini-2.0-flash'}}}}), inline_data=None, text=None)], role='tool')"}, {"role": "assistant", "content": "It seems like there are already agents named `DPAgent`, `EfficiencyAgent`, and `ApplicationAgent` that align well with the required expertise. I will use these existing agents to review the paper.\n\nNow, I will invoke each agent with the paper abstract and ask for a review and recommendation.\n"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'agent_name': 'DPAgent', 'prompt': \"Please provide a detailed review of the following paper, including strengths and weaknesses, and recommend Accept/Reject for ICLR 2023. Paper Title: Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping. 1 INTRODUCTION: Recent works on deep learning with differential privacy (DP) have substantially improved the computational efficiency (Subramani et al., 2021; Anil et al., 2021) and privacy-utility trade-off (Li et al., 2022a; Yu et al., 2022; De et al., 2022; Mehta et al., 2022), resulting in cost-effective private learning workflows with favourable utility under common levels of privacy guarantee. Common to most of these works is the use of differentially private stochastic gradient descent (DP-SGD) which clips per-example gradients (herein referred to as flat clipping) and noises their average before performing the parameter update based on a minibatch (Song et al., 2013; Bassily et al., 2014; Abadi et al., 2016). We explore whether further improvements in computational efficiency and privacy-utility trade-off are possible and provide affirmative answers for both directions, leveraging two instantiations of group-wise clipping for DP-SGD. DP-SGD is known to be computationally costly due to clipping per-example gradients. Instantiating per-example gradients and (potentially) normalizing them can incur both high memory and time costs in standard machine learning frameworks (Paszke et al., 2019; Frostig et al., 2018), and thus private machine learning with DP-SGD is reportedly much more memory demanding and/or slower than its non-private counterpart (Carlini et al., 2019; Hoory et al., 2021). Recent works have considerably improved the memory and time efficiency of DP-SGD with better software primitives (Subramani et al., 2021) and algorithms (Yousefpour et al., 2021; Lee & Kifer, 2021; Li et al., 2022b; Bu et al., 2022). Nevertheless, private learning still shows non-trivial increases in either memory usage or compute time when compared to non-private learning head-to-head. For instance, better software primitives do not eliminate the inherent increase in memory spending (Subramani et al., 2021), and improved algorithms only remove this memory overhead at the cost of extra runtime (Li et al., 2022b). The first research question we study is therefore Can private learning be as memory and time efficient (per-epoch) as non-private learning? We answer the above question affirmatively by giving an efficient implementation of per-layer clipping which had been studied in past works but not from a computational efficiency perspective (McMahan et al., 2018b; Dupuy et al., 2022). Clipping per-example gradients of separate neural networks layers (e.g., linear, convolution) separately allows clipping to be performed in conjunction with backpropagation. This results in private learning that is as memory-efficient and almost as timeefficient per training update as non-private learning for many small to moderate scale workflows of practical interest. While per-layer clipping with static clipping thresholds chosen by hand tends to underperform flat clipping, we show that per-layer clipping with adaptively estimated thresholds matches or outperforms flat clipping under given training epoch constraints, hence attaining similar or better task performances with less wall time. DP-SGD is known to (possibly) incur substantial performance losses compared to non-private learning. To improve the privacy-utility trade-off, several past works have leveraged large-scale publicly pretrained models (Yu et al., 2022; Li et al., 2022b; De et al., 2022; Mehta et al., 2022). These works observe that the privacy-utility trade-off improves with the use of larger (and thus better) pretrained models.1 We extend this research and study a second research question Can the privacy-utility trade-off be further improved with even better / larger pretrained models? To study this, we scale DP fine-tuning to work with one of the largest and most performant pretrained language models to date\u2014the 175 billion-parameter GPT-3. Weights of this model cannot be hosted in the memory of a single accelerator (e.g., GPU) and must be distributed across multiple devices. This presents challenges for flat clipping which calls for communicating per-example gradient norms across devices. To bypass these challenges, we turn to per-device clipping, where each device is prescribed a clipping threshold for clipping per-example gradients of the hosted model piece. Per-device clipping incurs no additional communication cost and allowed us to obtain with GPT-3 a private fine-tuning performance at \u03f5 = 1 that is better than what is attainable by non-privately fine-tuning the largest GPT-2 on a challenging summarization task. Our contributions are summarized below. (1) We show per-layer clipping enables clipping to be done in conjunction with backpropagation in DP optimization and results in private learning that is as memory-efficient and almost as fast per training update as non-private learning for many small to moderate scale workflows of interest. (2) We show adaptive per-layer clipping matches or outperforms flat clipping under fixed training epoch constraints, and thus attains similar or better task performances with less wall time. (3) We bypass scaling challenges associated with communicating per-example gradient norms with per-device clipping, with which we scale DP fine-tuning to work with the 175 billion-parameter GPT-3 and obtain improved task performance for a challenging summarization task at \u03f5 = 1. Finish the entire review and DO NOT STOP in the middle. GIVE A FINAL DECISION in the form of 'FINAL DECISION: <Accept/Reject>'.\"}, name='AskAgent'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"error\",\n  \"message\": \"Tool `AskAgent` failed to run.\",\n  \"output\": \"429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-1.5-pro'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-1.5-pro'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-1.5-pro'}}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}\"\n}\n```\n", "metadata": {"title": "Invoking `AskAgent` with \n```json\n{\n  \"agent_name\": \"DPAgent\",\n  \"prompt\": \"Please provide a detailed review of the following paper, including strengths and weaknesses, and recommend Accept/Reject for ICLR 2023. Paper Title: Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping. 1 INTRODUCTION: Recent works on deep learning with differential privacy (DP) have substantially improved the computational efficiency (Subramani et al., 2021; Anil et al., 2021) and privacy-utility trade-off (Li et al., 2022a; Yu et al., 2022; De et al., 2022; Mehta et al., 2022), resulting in cost-effective private learning workflows with favourable utility under common levels of privacy guarantee. Common to most of these works is the use of differentially private stochastic gradient descent (DP-SGD) which clips per-example gradients (herein referred to as flat clipping) and noises their average before performing the parameter update based on a minibatch (Song et al., 2013; Bassily et al., 2014; Abadi et al., 2016). We explore whether further improvements in computational efficiency and privacy-utility trade-off are possible and provide affirmative answers for both directions, leveraging two instantiations of group-wise clipping for DP-SGD. DP-SGD is known to be computationally costly due to clipping per-example gradients. Instantiating per-example gradients and (potentially) normalizing them can incur both high memory and time costs in standard machine learning frameworks (Paszke et al., 2019; Frostig et al., 2018), and thus private machine learning with DP-SGD is reportedly much more memory demanding and/or slower than its non-private counterpart (Carlini et al., 2019; Hoory et al., 2021). Recent works have considerably improved the memory and time efficiency of DP-SGD with better software primitives (Subramani et al., 2021) and algorithms (Yousefpour et al., 2021; Lee & Kifer, 2021; Li et al., 2022b; Bu et al., 2022). Nevertheless, private learning still shows non-trivial increases in either memory usage or compute time when compared to non-private learning head-to-head. For instance, better software primitives do not eliminate the inherent increase in memory spending (Subramani et al., 2021), and improved algorithms only remove this memory overhead at the cost of extra runtime (Li et al., 2022b). The first research question we study is therefore Can private learning be as memory and time efficient (per-epoch) as non-private learning? We answer the above question affirmatively by giving an efficient implementation of per-layer clipping which had been studied in past works but not from a computational efficiency perspective (McMahan et al., 2018b; Dupuy et al., 2022). Clipping per-example gradients of separate neural networks layers (e.g., linear, convolution) separately allows clipping to be performed in conjunction with backpropagation. This results in private learning that is as memory-efficient and almost as timeefficient per training update as non-private learning for many small to moderate scale workflows of practical interest. While per-layer clipping with static clipping thresholds chosen by hand tends to underperform flat clipping, we show that per-layer clipping with adaptively estimated thresholds matches or outperforms flat clipping under given training epoch constraints, hence attaining similar or better task performances with less wall time. DP-SGD is known to (possibly) incur substantial performance losses compared to non-private learning. To improve the privacy-utility trade-off, several past works have leveraged large-scale publicly pretrained models (Yu et al., 2022; Li et al., 2022b; De et al., 2022; Mehta et al., 2022). These works observe that the privacy-utility trade-off improves with the use of larger (and thus better) pretrained models.1 We extend this research and study a second research question Can the privacy-utility trade-off be further improved with even better / larger pretrained models? To study this, we scale DP fine-tuning to work with one of the largest and most performant pretrained language models to date\u2014the 175 billion-parameter GPT-3. Weights of this model cannot be hosted in the memory of a single accelerator (e.g., GPU) and must be distributed across multiple devices. This presents challenges for flat clipping which calls for communicating per-example gradient norms across devices. To bypass these challenges, we turn to per-device clipping, where each device is prescribed a clipping threshold for clipping per-example gradients of the hosted model piece. Per-device clipping incurs no additional communication cost and allowed us to obtain with GPT-3 a private fine-tuning performance at \u03f5 = 1 that is better than what is attainable by non-privately fine-tuning the largest GPT-2 on a challenging summarization task. Our contributions are summarized below. (1) We show per-layer clipping enables clipping to be done in conjunction with backpropagation in DP optimization and results in private learning that is as memory-efficient and almost as fast per training update as non-private learning for many small to moderate scale workflows of interest. (2) We show adaptive per-layer clipping matches or outperforms flat clipping under fixed training epoch constraints, and thus attains similar or better task performances with less wall time. (3) We bypass scaling challenges associated with communicating per-example gradient norms with per-device clipping, with which we scale DP fine-tuning to work with the 175 billion-parameter GPT-3 and obtain improved task performance for a challenging summarization task at \u03f5 = 1. Finish the entire review and DO NOT STOP in the middle. GIVE A FINAL DECISION in the form of 'FINAL DECISION: <Accept/Reject>'.\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AskAgent', response={'result': {'status': 'error', 'message': 'Tool `AskAgent` failed to run.', 'output': \"429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-1.5-pro'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-1.5-pro'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-1.5-pro'}}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}\"}}), inline_data=None, text=None)], role='tool')"}, {"role": "assistant", "content": "It seems I have exceeded my quota for the `gemini-1.5-pro` model. I will try using the `gemini-2.0-flash` model instead, as it is designed for faster and more cost-efficient operations. I will invoke the `ReviewerOne`, `ReviewerTwo`, and `ReviewerThree` agents.\n"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'prompt': \"Please provide a detailed review of the following paper, including strengths and weaknesses, and recommend Accept/Reject for ICLR 2023. Paper Title: Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping. 1 INTRODUCTION: Recent works on deep learning with differential privacy (DP) have substantially improved the computational efficiency (Subramani et al., 2021; Anil et al., 2021) and privacy-utility trade-off (Li et al., 2022a; Yu et al., 2022; De et al., 2022; Mehta et al., 2022), resulting in cost-effective private learning workflows with favourable utility under common levels of privacy guarantee. Common to most of these works is the use of differentially private stochastic gradient descent (DP-SGD) which clips per-example gradients (herein referred to as flat clipping) and noises their average before performing the parameter update based on a minibatch (Song et al., 2013; Bassily et al., 2014; Abadi et al., 2016). We explore whether further improvements in computational efficiency and privacy-utility trade-off are possible and provide affirmative answers for both directions, leveraging two instantiations of group-wise clipping for DP-SGD. DP-SGD is known to be computationally costly due to clipping per-example gradients. Instantiating per-example gradients and (potentially) normalizing them can incur both high memory and time costs in standard machine learning frameworks (Paszke et al., 2019; Frostig et al., 2018), and thus private machine learning with DP-SGD is reportedly much more memory demanding and/or slower than its non-private counterpart (Carlini et al., 2019; Hoory et al., 2021). Recent works have considerably improved the memory and time efficiency of DP-SGD with better software primitives (Subramani et al., 2021) and algorithms (Yousefpour et al., 2021; Lee & Kifer, 2021; Li et al., 2022b; Bu et al., 2022). Nevertheless, private learning still shows non-trivial increases in either memory usage or compute time when compared to non-private learning head-to-head. For instance, better software primitives do not eliminate the inherent increase in memory spending (Subramani et al., 2021), and improved algorithms only remove this memory overhead at the cost of extra runtime (Li et al., 2022b). The first research question we study is therefore Can private learning be as memory and time efficient (per-epoch) as non-private learning? We answer the above question affirmatively by giving an efficient implementation of per-layer clipping which had been studied in past works but not from a computational efficiency perspective (McMahan et al., 2018b; Dupuy et al., 2022). Clipping per-example gradients of separate neural networks layers (e.g., linear, convolution) separately allows clipping to be performed in conjunction with backpropagation. This results in private learning that is as memory-efficient and almost as timeefficient per training update as non-private learning for many small to moderate scale workflows of practical interest. While per-layer clipping with static clipping thresholds chosen by hand tends to underperform flat clipping, we show that per-layer clipping with adaptively estimated thresholds matches or outperforms flat clipping under given training epoch constraints, hence attaining similar or better task performances with less wall time. DP-SGD is known to (possibly) incur substantial performance losses compared to non-private learning. To improve the privacy-utility trade-off, several past works have leveraged large-scale publicly pretrained models (Yu et al., 2022; Li et al., 2022b; De et al., 2022; Mehta et al., 2022). These works observe that the privacy-utility trade-off improves with the use of larger (and thus better) pretrained models.1 We extend this research and study a second research question Can the privacy-utility trade-off be further improved with even better / larger pretrained models? To study this, we scale DP fine-tuning to work with one of the largest and most performant pretrained language models to date\u2014the 175 billion-parameter GPT-3. Weights of this model cannot be hosted in the memory of a single accelerator (e.g., GPU) and must be distributed across multiple devices. This presents challenges for flat clipping which calls for communicating per-example gradient norms across devices. To bypass these challenges, we turn to per-device clipping, where each device is prescribed a clipping threshold for clipping per-example gradients of the hosted model piece. Per-device clipping incurs no additional communication cost and allowed us to obtain with GPT-3 a private fine-tuning performance at \u03f5 = 1 that is better than what is attainable by non-privately fine-tuning the largest GPT-2 on a challenging summarization task. Our contributions are summarized below. (1) We show per-layer clipping enables clipping to be done in conjunction with backpropagation in DP optimization and results in private learning that is as memory-efficient and almost as fast per training update as non-private learning for many small to moderate scale workflows of interest. (2) We show adaptive per-layer clipping matches or outperforms flat clipping under fixed training epoch constraints, and thus attains similar or better task performances with less wall time. (3) We bypass scaling challenges associated with communicating per-example gradient norms with per-device clipping, with which we scale DP fine-tuning to work with the 175 billion-parameter GPT-3 and obtain improved task performance for a challenging summarization task at \u03f5 = 1. Finish the entire review and DO NOT STOP in the middle. GIVE A FINAL DECISION in the form of 'FINAL DECISION: <Accept/Reject>'.\", 'agent_name': 'ReviewerOne'}, name='AskAgent'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent has replied to the given prompt\",\n  \"output\": \"Okay, I will provide a detailed review of the paper \"Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping.\"\n\n**Summary of the Paper:**\n\nThe paper investigates improvements in differentially private deep learning (DP-DL) by exploring group-wise clipping techniques. It focuses on two main research questions: (1) Can private learning be as memory and time-efficient as non-private learning? and (2) Can the privacy-utility trade-off be further improved with even better/larger pretrained models? The authors propose and analyze per-layer clipping for efficiency and per-device clipping to scale DP fine-tuning to large models like GPT-3. They demonstrate that per-layer clipping can achieve comparable performance to flat clipping with better memory and time efficiency. Furthermore, they show that per-device clipping enables fine-tuning very large models like GPT-3 under differential privacy, achieving strong performance in summarization tasks.\n\n**Strengths:**\n\n*   **Addresses Important Challenges:** The paper tackles two critical challenges in DP-DL: computational efficiency and privacy-utility trade-off. These are significant bottlenecks in deploying DP-DL in practice.\n*   **Practical Focus:** The work is very practical. The authors don't just provide theoretical results; they focus on efficient implementations and scaling DP to large models. The experiments with GPT-3 are particularly compelling.\n*   **Novelty:** The application of per-device clipping to fine-tune GPT-3 under DP is novel and addresses a practical limitation of traditional DP-SGD when dealing with models that cannot fit on a single device. The exploration of adaptive per-layer clipping is also a worthwhile contribution.\n*   **Clear Research Questions:** The paper clearly defines the research questions it aims to address, which helps in understanding the motivation and contributions.\n*   **Empirical Evaluation:** The paper provides a thorough empirical evaluation of the proposed techniques, comparing them to existing methods on relevant benchmarks. The ablation studies (if present, though the description doesn't explicitly mention them) would further strengthen the empirical analysis.\n*   **Well-Written and Organized:** The paper is generally well-written and organized, making it easy to follow the main ideas and contributions.\n\n**Weaknesses:**\n\n*   **Lack of Theoretical Analysis:** While the paper is strong on the practical side, it lacks a deeper theoretical analysis of the proposed group-wise clipping methods. For example, it would be beneficial to have a theoretical justification for why adaptive per-layer clipping works well and how the choice of clipping thresholds affects the privacy-utility trade-off. The formal privacy analysis (using moments accountant or similar) is implicitly assumed but should be stated explicitly.\n*   **Adaptive Clipping Details:** The details of how the clipping thresholds are adaptively estimated for per-layer clipping are not fully specified in the introduction. A more detailed explanation of this adaptive mechanism is required. How is this adaptive threshold calculated and what are the hyperparameters involved? This is essential for reproducibility.\n*   **Comparison Baselines:** While the paper compares against flat clipping, it would be helpful to compare against other state-of-the-art DP-SGD variants, especially those that focus on improving efficiency or the privacy-utility trade-off. This would better contextualize the improvements achieved by the proposed methods.\n*   **Generalizability:** While the GPT-3 experiments are impressive, it is important to consider the generalizability of the per-device clipping approach to other large models and tasks. Are there any limitations or considerations when applying this technique to different model architectures or datasets?\n*   **Hyperparameter Tuning:** The paper should discuss the sensitivity of the results to hyperparameter choices, such as the clipping threshold, noise multiplier, and learning rate. It is important to understand how these parameters affect the performance and privacy guarantees of the proposed methods.\n\n**Recommendations for Improvement:**\n\n*   **Add Theoretical Analysis:** Include a section providing a more in-depth theoretical analysis of the proposed clipping methods, focusing on their privacy guarantees and convergence properties.\n*   **Explain Adaptive Clipping:** Provide a detailed explanation of the adaptive per-layer clipping mechanism, including the algorithm used to estimate the clipping thresholds and the hyperparameters involved.\n*   **Expand Baselines:** Compare against other state-of-the-art DP-SGD variants to better contextualize the improvements achieved by the proposed methods.\n*   **Discuss Generalizability:** Discuss the generalizability of the per-device clipping approach to other large models and tasks.\n*   **Analyze Hyperparameter Sensitivity:** Analyze the sensitivity of the results to hyperparameter choices.\n*   **Include Ablation Studies:** Add ablation studies to evaluate the impact of different components of the proposed methods (e.g., adaptive clipping, per-layer vs. per-device).\n*   **Explicitly State Privacy Analysis:** While DP is assumed, explicitly mentioning and referencing the privacy accounting method (e.g., moments accountant) is crucial.\n\n**Final Recommendation:**\n\nDespite the weaknesses mentioned above, the paper presents a valuable contribution to the field of differentially private deep learning. The practical focus, novel application of per-device clipping to large models, and empirical results are all compelling. The weaknesses can be addressed with further theoretical analysis and more detailed explanations of the methods. Therefore, I recommend **Accept** with the condition that the authors address the above-mentioned weaknesses in the final version.\n\n**FINAL DECISION: Accept**\n\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9.844716015\n}\n```\n", "metadata": {"title": "Invoking `AskAgent` with \n```json\n{\n  \"prompt\": \"Please provide a detailed review of the following paper, including strengths and weaknesses, and recommend Accept/Reject for ICLR 2023. Paper Title: Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping. 1 INTRODUCTION: Recent works on deep learning with differential privacy (DP) have substantially improved the computational efficiency (Subramani et al., 2021; Anil et al., 2021) and privacy-utility trade-off (Li et al., 2022a; Yu et al., 2022; De et al., 2022; Mehta et al., 2022), resulting in cost-effective private learning workflows with favourable utility under common levels of privacy guarantee. Common to most of these works is the use of differentially private stochastic gradient descent (DP-SGD) which clips per-example gradients (herein referred to as flat clipping) and noises their average before performing the parameter update based on a minibatch (Song et al., 2013; Bassily et al., 2014; Abadi et al., 2016). We explore whether further improvements in computational efficiency and privacy-utility trade-off are possible and provide affirmative answers for both directions, leveraging two instantiations of group-wise clipping for DP-SGD. DP-SGD is known to be computationally costly due to clipping per-example gradients. Instantiating per-example gradients and (potentially) normalizing them can incur both high memory and time costs in standard machine learning frameworks (Paszke et al., 2019; Frostig et al., 2018), and thus private machine learning with DP-SGD is reportedly much more memory demanding and/or slower than its non-private counterpart (Carlini et al., 2019; Hoory et al., 2021). Recent works have considerably improved the memory and time efficiency of DP-SGD with better software primitives (Subramani et al., 2021) and algorithms (Yousefpour et al., 2021; Lee & Kifer, 2021; Li et al., 2022b; Bu et al., 2022). Nevertheless, private learning still shows non-trivial increases in either memory usage or compute time when compared to non-private learning head-to-head. For instance, better software primitives do not eliminate the inherent increase in memory spending (Subramani et al., 2021), and improved algorithms only remove this memory overhead at the cost of extra runtime (Li et al., 2022b). The first research question we study is therefore Can private learning be as memory and time efficient (per-epoch) as non-private learning? We answer the above question affirmatively by giving an efficient implementation of per-layer clipping which had been studied in past works but not from a computational efficiency perspective (McMahan et al., 2018b; Dupuy et al., 2022). Clipping per-example gradients of separate neural networks layers (e.g., linear, convolution) separately allows clipping to be performed in conjunction with backpropagation. This results in private learning that is as memory-efficient and almost as timeefficient per training update as non-private learning for many small to moderate scale workflows of practical interest. While per-layer clipping with static clipping thresholds chosen by hand tends to underperform flat clipping, we show that per-layer clipping with adaptively estimated thresholds matches or outperforms flat clipping under given training epoch constraints, hence attaining similar or better task performances with less wall time. DP-SGD is known to (possibly) incur substantial performance losses compared to non-private learning. To improve the privacy-utility trade-off, several past works have leveraged large-scale publicly pretrained models (Yu et al., 2022; Li et al., 2022b; De et al., 2022; Mehta et al., 2022). These works observe that the privacy-utility trade-off improves with the use of larger (and thus better) pretrained models.1 We extend this research and study a second research question Can the privacy-utility trade-off be further improved with even better / larger pretrained models? To study this, we scale DP fine-tuning to work with one of the largest and most performant pretrained language models to date\u2014the 175 billion-parameter GPT-3. Weights of this model cannot be hosted in the memory of a single accelerator (e.g., GPU) and must be distributed across multiple devices. This presents challenges for flat clipping which calls for communicating per-example gradient norms across devices. To bypass these challenges, we turn to per-device clipping, where each device is prescribed a clipping threshold for clipping per-example gradients of the hosted model piece. Per-device clipping incurs no additional communication cost and allowed us to obtain with GPT-3 a private fine-tuning performance at \u03f5 = 1 that is better than what is attainable by non-privately fine-tuning the largest GPT-2 on a challenging summarization task. Our contributions are summarized below. (1) We show per-layer clipping enables clipping to be done in conjunction with backpropagation in DP optimization and results in private learning that is as memory-efficient and almost as fast per training update as non-private learning for many small to moderate scale workflows of interest. (2) We show adaptive per-layer clipping matches or outperforms flat clipping under fixed training epoch constraints, and thus attains similar or better task performances with less wall time. (3) We bypass scaling challenges associated with communicating per-example gradient norms with per-device clipping, with which we scale DP fine-tuning to work with the 175 billion-parameter GPT-3 and obtain improved task performance for a challenging summarization task at \u03f5 = 1. Finish the entire review and DO NOT STOP in the middle. GIVE A FINAL DECISION in the form of 'FINAL DECISION: <Accept/Reject>'.\",\n  \"agent_name\": \"ReviewerOne\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AskAgent', response={'result': {'status': 'success', 'message': 'Agent has replied to the given prompt', 'output': 'Okay, I will provide a detailed review of the paper \"Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping.\"\\n\\n**Summary of the Paper:**\\n\\nThe paper investigates improvements in differentially private deep learning (DP-DL) by exploring group-wise clipping techniques. It focuses on two main research questions: (1) Can private learning be as memory and time-efficient as non-private learning? and (2) Can the privacy-utility trade-off be further improved with even better/larger pretrained models? The authors propose and analyze per-layer clipping for efficiency and per-device clipping to scale DP fine-tuning to large models like GPT-3. They demonstrate that per-layer clipping can achieve comparable performance to flat clipping with better memory and time efficiency. Furthermore, they show that per-device clipping enables fine-tuning very large models like GPT-3 under differential privacy, achieving strong performance in summarization tasks.\\n\\n**Strengths:**\\n\\n*   **Addresses Important Challenges:** The paper tackles two critical challenges in DP-DL: computational efficiency and privacy-utility trade-off. These are significant bottlenecks in deploying DP-DL in practice.\\n*   **Practical Focus:** The work is very practical. The authors don\\'t just provide theoretical results; they focus on efficient implementations and scaling DP to large models. The experiments with GPT-3 are particularly compelling.\\n*   **Novelty:** The application of per-device clipping to fine-tune GPT-3 under DP is novel and addresses a practical limitation of traditional DP-SGD when dealing with models that cannot fit on a single device. The exploration of adaptive per-layer clipping is also a worthwhile contribution.\\n*   **Clear Research Questions:** The paper clearly defines the research questions it aims to address, which helps in understanding the motivation and contributions.\\n*   **Empirical Evaluation:** The paper provides a thorough empirical evaluation of the proposed techniques, comparing them to existing methods on relevant benchmarks. The ablation studies (if present, though the description doesn\\'t explicitly mention them) would further strengthen the empirical analysis.\\n*   **Well-Written and Organized:** The paper is generally well-written and organized, making it easy to follow the main ideas and contributions.\\n\\n**Weaknesses:**\\n\\n*   **Lack of Theoretical Analysis:** While the paper is strong on the practical side, it lacks a deeper theoretical analysis of the proposed group-wise clipping methods. For example, it would be beneficial to have a theoretical justification for why adaptive per-layer clipping works well and how the choice of clipping thresholds affects the privacy-utility trade-off. The formal privacy analysis (using moments accountant or similar) is implicitly assumed but should be stated explicitly.\\n*   **Adaptive Clipping Details:** The details of how the clipping thresholds are adaptively estimated for per-layer clipping are not fully specified in the introduction. A more detailed explanation of this adaptive mechanism is required. How is this adaptive threshold calculated and what are the hyperparameters involved? This is essential for reproducibility.\\n*   **Comparison Baselines:** While the paper compares against flat clipping, it would be helpful to compare against other state-of-the-art DP-SGD variants, especially those that focus on improving efficiency or the privacy-utility trade-off. This would better contextualize the improvements achieved by the proposed methods.\\n*   **Generalizability:** While the GPT-3 experiments are impressive, it is important to consider the generalizability of the per-device clipping approach to other large models and tasks. Are there any limitations or considerations when applying this technique to different model architectures or datasets?\\n*   **Hyperparameter Tuning:** The paper should discuss the sensitivity of the results to hyperparameter choices, such as the clipping threshold, noise multiplier, and learning rate. It is important to understand how these parameters affect the performance and privacy guarantees of the proposed methods.\\n\\n**Recommendations for Improvement:**\\n\\n*   **Add Theoretical Analysis:** Include a section providing a more in-depth theoretical analysis of the proposed clipping methods, focusing on their privacy guarantees and convergence properties.\\n*   **Explain Adaptive Clipping:** Provide a detailed explanation of the adaptive per-layer clipping mechanism, including the algorithm used to estimate the clipping thresholds and the hyperparameters involved.\\n*   **Expand Baselines:** Compare against other state-of-the-art DP-SGD variants to better contextualize the improvements achieved by the proposed methods.\\n*   **Discuss Generalizability:** Discuss the generalizability of the per-device clipping approach to other large models and tasks.\\n*   **Analyze Hyperparameter Sensitivity:** Analyze the sensitivity of the results to hyperparameter choices.\\n*   **Include Ablation Studies:** Add ablation studies to evaluate the impact of different components of the proposed methods (e.g., adaptive clipping, per-layer vs. per-device).\\n*   **Explicitly State Privacy Analysis:** While DP is assumed, explicitly mentioning and referencing the privacy accounting method (e.g., moments accountant) is crucial.\\n\\n**Final Recommendation:**\\n\\nDespite the weaknesses mentioned above, the paper presents a valuable contribution to the field of differentially private deep learning. The practical focus, novel application of per-device clipping to large models, and empirical results are all compelling. The weaknesses can be addressed with further theoretical analysis and more detailed explanations of the methods. Therefore, I recommend **Accept** with the condition that the authors address the above-mentioned weaknesses in the final version.\\n\\n**FINAL DECISION: Accept**\\n', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9.844716015}}), inline_data=None, text=None)], role='tool')"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'prompt': \"Please provide a detailed review of the following paper, including strengths and weaknesses, and recommend Accept/Reject for ICLR 2023. Paper Title: Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping. 1 INTRODUCTION: Recent works on deep learning with differential privacy (DP) have substantially improved the computational efficiency (Subramani et al., 2021; Anil et al., 2021) and privacy-utility trade-off (Li et al., 2022a; Yu et al., 2022; De et al., 2022; Mehta et al., 2022), resulting in cost-effective private learning workflows with favourable utility under common levels of privacy guarantee. Common to most of these works is the use of differentially private stochastic gradient descent (DP-SGD) which clips per-example gradients (herein referred to as flat clipping) and noises their average before performing the parameter update based on a minibatch (Song et al., 2013; Bassily et al., 2014; Abadi et al., 2016). We explore whether further improvements in computational efficiency and privacy-utility trade-off are possible and provide affirmative answers for both directions, leveraging two instantiations of group-wise clipping for DP-SGD. DP-SGD is known to be computationally costly due to clipping per-example gradients. Instantiating per-example gradients and (potentially) normalizing them can incur both high memory and time costs in standard machine learning frameworks (Paszke et al., 2019; Frostig et al., 2018), and thus private machine learning with DP-SGD is reportedly much more memory demanding and/or slower than its non-private counterpart (Carlini et al., 2019; Hoory et al., 2021). Recent works have considerably improved the memory and time efficiency of DP-SGD with better software primitives (Subramani et al., 2021) and algorithms (Yousefpour et al., 2021; Lee & Kifer, 2021; Li et al., 2022b; Bu et al., 2022). Nevertheless, private learning still shows non-trivial increases in either memory usage or compute time when compared to non-private learning head-to-head. For instance, better software primitives do not eliminate the inherent increase in memory spending (Subramani et al., 2021), and improved algorithms only remove this memory overhead at the cost of extra runtime (Li et al., 2022b). The first research question we study is therefore Can private learning be as memory and time efficient (per-epoch) as non-private learning? We answer the above question affirmatively by giving an efficient implementation of per-layer clipping which had been studied in past works but not from a computational efficiency perspective (McMahan et al., 2018b; Dupuy et al., 2022). Clipping per-example gradients of separate neural networks layers (e.g., linear, convolution) separately allows clipping to be performed in conjunction with backpropagation. This results in private learning that is as memory-efficient and almost as timeefficient per training update as non-private learning for many small to moderate scale workflows of practical interest. While per-layer clipping with static clipping thresholds chosen by hand tends to underperform flat clipping, we show that per-layer clipping with adaptively estimated thresholds matches or outperforms flat clipping under given training epoch constraints, hence attaining similar or better task performances with less wall time. DP-SGD is known to (possibly) incur substantial performance losses compared to non-private learning. To improve the privacy-utility trade-off, several past works have leveraged large-scale publicly pretrained models (Yu et al., 2022; Li et al., 2022b; De et al., 2022; Mehta et al., 2022). These works observe that the privacy-utility trade-off improves with the use of larger (and thus better) pretrained models.1 We extend this research and study a second research question Can the privacy-utility trade-off be further improved with even better / larger pretrained models? To study this, we scale DP fine-tuning to work with one of the largest and most performant pretrained language models to date\u2014the 175 billion-parameter GPT-3. Weights of this model cannot be hosted in the memory of a single accelerator (e.g., GPU) and must be distributed across multiple devices. This presents challenges for flat clipping which calls for communicating per-example gradient norms across devices. To bypass these challenges, we turn to per-device clipping, where each device is prescribed a clipping threshold for clipping per-example gradients of the hosted model piece. Per-device clipping incurs no additional communication cost and allowed us to obtain with GPT-3 a private fine-tuning performance at \u03f5 = 1 that is better than what is attainable by non-privately fine-tuning the largest GPT-2 on a challenging summarization task. Our contributions are summarized below. (1) We show per-layer clipping enables clipping to be done in conjunction with backpropagation in DP optimization and results in private learning that is as memory-efficient and almost as fast per training update as non-private learning for many small to moderate scale workflows of interest. (2) We show adaptive per-layer clipping matches or outperforms flat clipping under fixed training epoch constraints, and thus attains similar or better task performances with less wall time. (3) We bypass scaling challenges associated with communicating per-example gradient norms with per-device clipping, with which we scale DP fine-tuning to work with the 175 billion-parameter GPT-3 and obtain improved task performance for a challenging summarization task at \u03f5 = 1. Finish the entire review and DO NOT STOP in the middle. GIVE A FINAL DECISION in the form of 'FINAL DECISION: <Accept/Reject>'.\", 'agent_name': 'ReviewerTwo'}, name='AskAgent'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent has replied to the given prompt\",\n  \"output\": \"Okay, I will provide a detailed review of the paper, including strengths, weaknesses, and a recommendation.\n\n**Title:** Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping\n\n**Summary:**\n\nThe paper explores improvements to Differentially Private Stochastic Gradient Descent (DP-SGD) by focusing on group-wise clipping strategies, specifically per-layer and per-device clipping.  The authors aim to address two key limitations of DP-SGD: computational inefficiency (memory and time costs) and the privacy-utility trade-off. They demonstrate that per-layer clipping can be as memory-efficient and almost as time-efficient as non-private learning for smaller models.  Furthermore, adaptive per-layer clipping can match or outperform flat clipping.  For large models, they introduce per-device clipping to enable DP fine-tuning of the 175B parameter GPT-3, achieving state-of-the-art privacy-utility trade-offs at epsilon=1.\n\n**Strengths:**\n\n*   **Addresses Important Limitations:** The paper directly tackles two critical challenges in DP-SGD: computational overhead and the privacy-utility trade-off. These are well-recognized bottlenecks in the field, making the paper highly relevant.\n*   **Practical Focus and Empirical Validation:** The paper emphasizes practical implementation and empirical evaluation. The claims are supported by experimental results, demonstrating the effectiveness of the proposed techniques. The experiments on GPT-3 are especially impressive.\n*   **Clear Contributions:** The contributions are clearly stated and well-motivated.  The paper highlights the benefits of per-layer and per-device clipping in terms of efficiency and performance.\n*   **Scalability:**  The per-device clipping method is a significant contribution, as it allows DP-SGD to be applied to extremely large models like GPT-3, which was previously a major hurdle.\n*   **Strong Results:** The finding that privately fine-tuning GPT-3 achieves better performance than non-privately fine-tuning GPT-2 on a summarization task is a compelling result that underscores the potential of the proposed approach.\n*   **Well Written:** The paper is well-written and easy to follow. The motivation and methodology are clearly explained.\n\n**Weaknesses:**\n\n*   **Limited Novelty in Per-Layer Clipping:** While the paper demonstrates the practical benefits of per-layer clipping, the technique itself is not entirely novel, as the authors acknowledge.  The novelty lies more in the efficient implementation and adaptive thresholding, but this could be emphasized more.\n*   **Lack of Theoretical Analysis:** The paper primarily focuses on empirical results. A more in-depth theoretical analysis of the convergence and privacy properties of per-layer and per-device clipping could strengthen the paper.  For example, a discussion of how the choice of layers impacts the overall privacy bound could be valuable.\n*   **Hyperparameter Sensitivity:** The paper could benefit from a more detailed discussion of the hyperparameters involved in adaptive clipping, and how they affect performance and privacy. How sensitive are the results to the adaptive clipping parameters?\n*   **Limited Comparison to Alternative DP Methods:** While the paper compares against flat clipping, a comparison against other recent DP optimization techniques beyond just flat clipping would provide a broader context for the results.\n\n**Overall Assessment:**\n\nThe paper presents a valuable contribution to the field of differentially private deep learning. The practical focus, strong empirical results, and successful application to a large language model like GPT-3 make it a significant advancement. While the novelty of per-layer clipping is somewhat limited, the efficient implementation and adaptive thresholding are worthwhile contributions. The per-device clipping strategy is particularly impactful, addressing a major scalability bottleneck. The paper is well-written and clearly presents its findings.\n\n**Recommendation:**\n\nFINAL DECISION: Accept\n\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9.844573555\n}\n```\n", "metadata": {"title": "Invoking `AskAgent` with \n```json\n{\n  \"prompt\": \"Please provide a detailed review of the following paper, including strengths and weaknesses, and recommend Accept/Reject for ICLR 2023. Paper Title: Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping. 1 INTRODUCTION: Recent works on deep learning with differential privacy (DP) have substantially improved the computational efficiency (Subramani et al., 2021; Anil et al., 2021) and privacy-utility trade-off (Li et al., 2022a; Yu et al., 2022; De et al., 2022; Mehta et al., 2022), resulting in cost-effective private learning workflows with favourable utility under common levels of privacy guarantee. Common to most of these works is the use of differentially private stochastic gradient descent (DP-SGD) which clips per-example gradients (herein referred to as flat clipping) and noises their average before performing the parameter update based on a minibatch (Song et al., 2013; Bassily et al., 2014; Abadi et al., 2016). We explore whether further improvements in computational efficiency and privacy-utility trade-off are possible and provide affirmative answers for both directions, leveraging two instantiations of group-wise clipping for DP-SGD. DP-SGD is known to be computationally costly due to clipping per-example gradients. Instantiating per-example gradients and (potentially) normalizing them can incur both high memory and time costs in standard machine learning frameworks (Paszke et al., 2019; Frostig et al., 2018), and thus private machine learning with DP-SGD is reportedly much more memory demanding and/or slower than its non-private counterpart (Carlini et al., 2019; Hoory et al., 2021). Recent works have considerably improved the memory and time efficiency of DP-SGD with better software primitives (Subramani et al., 2021) and algorithms (Yousefpour et al., 2021; Lee & Kifer, 2021; Li et al., 2022b; Bu et al., 2022). Nevertheless, private learning still shows non-trivial increases in either memory usage or compute time when compared to non-private learning head-to-head. For instance, better software primitives do not eliminate the inherent increase in memory spending (Subramani et al., 2021), and improved algorithms only remove this memory overhead at the cost of extra runtime (Li et al., 2022b). The first research question we study is therefore Can private learning be as memory and time efficient (per-epoch) as non-private learning? We answer the above question affirmatively by giving an efficient implementation of per-layer clipping which had been studied in past works but not from a computational efficiency perspective (McMahan et al., 2018b; Dupuy et al., 2022). Clipping per-example gradients of separate neural networks layers (e.g., linear, convolution) separately allows clipping to be performed in conjunction with backpropagation. This results in private learning that is as memory-efficient and almost as timeefficient per training update as non-private learning for many small to moderate scale workflows of practical interest. While per-layer clipping with static clipping thresholds chosen by hand tends to underperform flat clipping, we show that per-layer clipping with adaptively estimated thresholds matches or outperforms flat clipping under given training epoch constraints, hence attaining similar or better task performances with less wall time. DP-SGD is known to (possibly) incur substantial performance losses compared to non-private learning. To improve the privacy-utility trade-off, several past works have leveraged large-scale publicly pretrained models (Yu et al., 2022; Li et al., 2022b; De et al., 2022; Mehta et al., 2022). These works observe that the privacy-utility trade-off improves with the use of larger (and thus better) pretrained models.1 We extend this research and study a second research question Can the privacy-utility trade-off be further improved with even better / larger pretrained models? To study this, we scale DP fine-tuning to work with one of the largest and most performant pretrained language models to date\u2014the 175 billion-parameter GPT-3. Weights of this model cannot be hosted in the memory of a single accelerator (e.g., GPU) and must be distributed across multiple devices. This presents challenges for flat clipping which calls for communicating per-example gradient norms across devices. To bypass these challenges, we turn to per-device clipping, where each device is prescribed a clipping threshold for clipping per-example gradients of the hosted model piece. Per-device clipping incurs no additional communication cost and allowed us to obtain with GPT-3 a private fine-tuning performance at \u03f5 = 1 that is better than what is attainable by non-privately fine-tuning the largest GPT-2 on a challenging summarization task. Our contributions are summarized below. (1) We show per-layer clipping enables clipping to be done in conjunction with backpropagation in DP optimization and results in private learning that is as memory-efficient and almost as fast per training update as non-private learning for many small to moderate scale workflows of interest. (2) We show adaptive per-layer clipping matches or outperforms flat clipping under fixed training epoch constraints, and thus attains similar or better task performances with less wall time. (3) We bypass scaling challenges associated with communicating per-example gradient norms with per-device clipping, with which we scale DP fine-tuning to work with the 175 billion-parameter GPT-3 and obtain improved task performance for a challenging summarization task at \u03f5 = 1. Finish the entire review and DO NOT STOP in the middle. GIVE A FINAL DECISION in the form of 'FINAL DECISION: <Accept/Reject>'.\",\n  \"agent_name\": \"ReviewerTwo\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AskAgent', response={'result': {'status': 'success', 'message': 'Agent has replied to the given prompt', 'output': 'Okay, I will provide a detailed review of the paper, including strengths, weaknesses, and a recommendation.\\n\\n**Title:** Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping\\n\\n**Summary:**\\n\\nThe paper explores improvements to Differentially Private Stochastic Gradient Descent (DP-SGD) by focusing on group-wise clipping strategies, specifically per-layer and per-device clipping.  The authors aim to address two key limitations of DP-SGD: computational inefficiency (memory and time costs) and the privacy-utility trade-off. They demonstrate that per-layer clipping can be as memory-efficient and almost as time-efficient as non-private learning for smaller models.  Furthermore, adaptive per-layer clipping can match or outperform flat clipping.  For large models, they introduce per-device clipping to enable DP fine-tuning of the 175B parameter GPT-3, achieving state-of-the-art privacy-utility trade-offs at epsilon=1.\\n\\n**Strengths:**\\n\\n*   **Addresses Important Limitations:** The paper directly tackles two critical challenges in DP-SGD: computational overhead and the privacy-utility trade-off. These are well-recognized bottlenecks in the field, making the paper highly relevant.\\n*   **Practical Focus and Empirical Validation:** The paper emphasizes practical implementation and empirical evaluation. The claims are supported by experimental results, demonstrating the effectiveness of the proposed techniques. The experiments on GPT-3 are especially impressive.\\n*   **Clear Contributions:** The contributions are clearly stated and well-motivated.  The paper highlights the benefits of per-layer and per-device clipping in terms of efficiency and performance.\\n*   **Scalability:**  The per-device clipping method is a significant contribution, as it allows DP-SGD to be applied to extremely large models like GPT-3, which was previously a major hurdle.\\n*   **Strong Results:** The finding that privately fine-tuning GPT-3 achieves better performance than non-privately fine-tuning GPT-2 on a summarization task is a compelling result that underscores the potential of the proposed approach.\\n*   **Well Written:** The paper is well-written and easy to follow. The motivation and methodology are clearly explained.\\n\\n**Weaknesses:**\\n\\n*   **Limited Novelty in Per-Layer Clipping:** While the paper demonstrates the practical benefits of per-layer clipping, the technique itself is not entirely novel, as the authors acknowledge.  The novelty lies more in the efficient implementation and adaptive thresholding, but this could be emphasized more.\\n*   **Lack of Theoretical Analysis:** The paper primarily focuses on empirical results. A more in-depth theoretical analysis of the convergence and privacy properties of per-layer and per-device clipping could strengthen the paper.  For example, a discussion of how the choice of layers impacts the overall privacy bound could be valuable.\\n*   **Hyperparameter Sensitivity:** The paper could benefit from a more detailed discussion of the hyperparameters involved in adaptive clipping, and how they affect performance and privacy. How sensitive are the results to the adaptive clipping parameters?\\n*   **Limited Comparison to Alternative DP Methods:** While the paper compares against flat clipping, a comparison against other recent DP optimization techniques beyond just flat clipping would provide a broader context for the results.\\n\\n**Overall Assessment:**\\n\\nThe paper presents a valuable contribution to the field of differentially private deep learning. The practical focus, strong empirical results, and successful application to a large language model like GPT-3 make it a significant advancement. While the novelty of per-layer clipping is somewhat limited, the efficient implementation and adaptive thresholding are worthwhile contributions. The per-device clipping strategy is particularly impactful, addressing a major scalability bottleneck. The paper is well-written and clearly presents its findings.\\n\\n**Recommendation:**\\n\\nFINAL DECISION: Accept\\n', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9.844573555}}), inline_data=None, text=None)], role='tool')"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'prompt': \"Please provide a detailed review of the following paper, including strengths and weaknesses, and recommend Accept/Reject for ICLR 2023. Paper Title: Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping. 1 INTRODUCTION: Recent works on deep learning with differential privacy (DP) have substantially improved the computational efficiency (Subramani et al., 2021; Anil et al., 2021) and privacy-utility trade-off (Li et al., 2022a; Yu et al., 2022; De et al., 2022; Mehta et al., 2022), resulting in cost-effective private learning workflows with favourable utility under common levels of privacy guarantee. Common to most of these works is the use of differentially private stochastic gradient descent (DP-SGD) which clips per-example gradients (herein referred to as flat clipping) and noises their average before performing the parameter update based on a minibatch (Song et al., 2013; Bassily et al., 2014; Abadi et al., 2016). We explore whether further improvements in computational efficiency and privacy-utility trade-off are possible and provide affirmative answers for both directions, leveraging two instantiations of group-wise clipping for DP-SGD. DP-SGD is known to be computationally costly due to clipping per-example gradients. Instantiating per-example gradients and (potentially) normalizing them can incur both high memory and time costs in standard machine learning frameworks (Paszke et al., 2019; Frostig et al., 2018), and thus private machine learning with DP-SGD is reportedly much more memory demanding and/or slower than its non-private counterpart (Carlini et al., 2019; Hoory et al., 2021). Recent works have considerably improved the memory and time efficiency of DP-SGD with better software primitives (Subramani et al., 2021) and algorithms (Yousefpour et al., 2021; Lee & Kifer, 2021; Li et al., 2022b; Bu et al., 2022). Nevertheless, private learning still shows non-trivial increases in either memory usage or compute time when compared to non-private learning head-to-head. For instance, better software primitives do not eliminate the inherent increase in memory spending (Subramani et al., 2021), and improved algorithms only remove this memory overhead at the cost of extra runtime (Li et al., 2022b). The first research question we study is therefore Can private learning be as memory and time efficient (per-epoch) as non-private learning? We answer the above question affirmatively by giving an efficient implementation of per-layer clipping which had been studied in past works but not from a computational efficiency perspective (McMahan et al., 2018b; Dupuy et al., 2022). Clipping per-example gradients of separate neural networks layers (e.g., linear, convolution) separately allows clipping to be performed in conjunction with backpropagation. This results in private learning that is as memory-efficient and almost as timeefficient per training update as non-private learning for many small to moderate scale workflows of practical interest. While per-layer clipping with static clipping thresholds chosen by hand tends to underperform flat clipping, we show that per-layer clipping with adaptively estimated thresholds matches or outperforms flat clipping under given training epoch constraints, hence attaining similar or better task performances with less wall time. DP-SGD is known to (possibly) incur substantial performance losses compared to non-private learning. To improve the privacy-utility trade-off, several past works have leveraged large-scale publicly pretrained models (Yu et al., 2022; Li et al., 2022b; De et al., 2022; Mehta et al., 2022). These works observe that the privacy-utility trade-off improves with the use of larger (and thus better) pretrained models.1 We extend this research and study a second research question Can the privacy-utility trade-off be further improved with even better / larger pretrained models? To study this, we scale DP fine-tuning to work with one of the largest and most performant pretrained language models to date\u2014the 175 billion-parameter GPT-3. Weights of this model cannot be hosted in the memory of a single accelerator (e.g., GPU) and must be distributed across multiple devices. This presents challenges for flat clipping which calls for communicating per-example gradient norms across devices. To bypass these challenges, we turn to per-device clipping, where each device is prescribed a clipping threshold for clipping per-example gradients of the hosted model piece. Per-device clipping incurs no additional communication cost and allowed us to obtain with GPT-3 a private fine-tuning performance at \u03f5 = 1 that is better than what is attainable by non-privately fine-tuning the largest GPT-2 on a challenging summarization task. Our contributions are summarized below. (1) We show per-layer clipping enables clipping to be done in conjunction with backpropagation in DP optimization and results in private learning that is as memory-efficient and almost as fast per training update as non-private learning for many small to moderate scale workflows of interest. (2) We show adaptive per-layer clipping matches or outperforms flat clipping under fixed training epoch constraints, and thus attains similar or better task performances with less wall time. (3) We bypass scaling challenges associated with communicating per-example gradient norms with per-device clipping, with which we scale DP fine-tuning to work with the 175 billion-parameter GPT-3 and obtain improved task performance for a challenging summarization task at \u03f5 = 1. Finish the entire review and DO NOT STOP in the middle. GIVE A FINAL DECISION in the form of 'FINAL DECISION: <Accept/Reject>'.\", 'agent_name': 'ReviewerThree'}, name='AskAgent'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent has replied to the given prompt\",\n  \"output\": \"## Review of \"Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping\"\n\nThis paper explores the computational efficiency and privacy-utility trade-offs of differentially private deep learning (DP-DL) using group-wise clipping strategies. The authors investigate two main research questions: 1) Can private learning be as memory and time efficient as non-private learning? and 2) Can the privacy-utility trade-off be further improved with larger pretrained models? They propose and evaluate per-layer and per-device clipping strategies within the DP-SGD framework to address these questions.\n\n**Strengths:**\n\n*   **Addresses Important Problems:** The paper tackles two crucial challenges in DP-DL: computational overhead and utility degradation. These are significant bottlenecks that hinder the wider adoption of DP-DL in practice.\n*   **Clear Research Questions and Contributions:** The research questions are clearly defined, and the contributions are well-articulated in the introduction and conclusion.\n*   **Practical and Scalable Solutions:** The proposed per-layer and per-device clipping strategies offer practical solutions for improving computational efficiency and scaling DP-DL to large models.  The focus on memory efficiency is particularly valuable.\n*   **Strong Experimental Results:** The experimental results support the claims made in the paper. The authors demonstrate that per-layer clipping can achieve comparable or better performance than flat clipping with reduced computational overhead. They also showcase the successful application of per-device clipping to fine-tune GPT-3, achieving state-of-the-art results in private fine-tuning. The experiments cover a range of datasets and model sizes.\n*   **Well-written and Organized:** The paper is generally well-written and organized, making it easy to follow the authors' reasoning and understand their contributions.\n*   **Impactful Application:**  Demonstrating DP fine-tuning of GPT-3 is a significant achievement and a strong contribution to the field. This highlights the potential of the proposed methods for real-world applications.\n\n**Weaknesses:**\n\n*   **Limited Theoretical Analysis:** While the paper presents strong empirical results, the theoretical analysis of the proposed clipping strategies is limited.  A deeper understanding of the privacy implications and convergence properties of per-layer and per-device clipping could further strengthen the paper.  For example, is there a theoretical reason to believe adaptive per-layer clipping can match or outperform flat clipping?\n*   **Adaptive Clipping Threshold Tuning:**  The details of how the adaptive clipping thresholds are chosen for per-layer clipping could be expanded. The sensitivity of the performance to the choice of adaptive clipping method should be discussed, potentially including ablation studies of different strategies.\n*   **Hyperparameter Sensitivity:**  The paper could benefit from a more detailed discussion on the sensitivity of the results to different hyperparameters, such as the clipping norm, learning rate, and noise multiplier. Providing guidelines for choosing these hyperparameters for different datasets and models would be valuable for practitioners.\n*   **Comparison to Alternative DP-SGD Optimizations:** The related work section mentions several recent works on improving DP-SGD. While the paper compares against flat clipping (a common baseline), it would be beneficial to explicitly compare the proposed methods against other state-of-the-art DP-SGD optimization techniques in terms of both computational efficiency and privacy-utility trade-off.\n\n**Overall Assessment:**\n\nThis paper presents a valuable contribution to the field of differentially private deep learning. The proposed per-layer and per-device clipping strategies offer practical solutions for improving computational efficiency and scaling DP-DL to large models. The experimental results are strong and support the claims made in the paper. While the theoretical analysis could be strengthened and the hyperparameter sensitivity could be discussed in more detail, the paper's practical impact and clear presentation make it a strong candidate for acceptance.\n\n**FINAL DECISION: Accept**\n\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9.844431095\n}\n```\n", "metadata": {"title": "Invoking `AskAgent` with \n```json\n{\n  \"prompt\": \"Please provide a detailed review of the following paper, including strengths and weaknesses, and recommend Accept/Reject for ICLR 2023. Paper Title: Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping. 1 INTRODUCTION: Recent works on deep learning with differential privacy (DP) have substantially improved the computational efficiency (Subramani et al., 2021; Anil et al., 2021) and privacy-utility trade-off (Li et al., 2022a; Yu et al., 2022; De et al., 2022; Mehta et al., 2022), resulting in cost-effective private learning workflows with favourable utility under common levels of privacy guarantee. Common to most of these works is the use of differentially private stochastic gradient descent (DP-SGD) which clips per-example gradients (herein referred to as flat clipping) and noises their average before performing the parameter update based on a minibatch (Song et al., 2013; Bassily et al., 2014; Abadi et al., 2016). We explore whether further improvements in computational efficiency and privacy-utility trade-off are possible and provide affirmative answers for both directions, leveraging two instantiations of group-wise clipping for DP-SGD. DP-SGD is known to be computationally costly due to clipping per-example gradients. Instantiating per-example gradients and (potentially) normalizing them can incur both high memory and time costs in standard machine learning frameworks (Paszke et al., 2019; Frostig et al., 2018), and thus private machine learning with DP-SGD is reportedly much more memory demanding and/or slower than its non-private counterpart (Carlini et al., 2019; Hoory et al., 2021). Recent works have considerably improved the memory and time efficiency of DP-SGD with better software primitives (Subramani et al., 2021) and algorithms (Yousefpour et al., 2021; Lee & Kifer, 2021; Li et al., 2022b; Bu et al., 2022). Nevertheless, private learning still shows non-trivial increases in either memory usage or compute time when compared to non-private learning head-to-head. For instance, better software primitives do not eliminate the inherent increase in memory spending (Subramani et al., 2021), and improved algorithms only remove this memory overhead at the cost of extra runtime (Li et al., 2022b). The first research question we study is therefore Can private learning be as memory and time efficient (per-epoch) as non-private learning? We answer the above question affirmatively by giving an efficient implementation of per-layer clipping which had been studied in past works but not from a computational efficiency perspective (McMahan et al., 2018b; Dupuy et al., 2022). Clipping per-example gradients of separate neural networks layers (e.g., linear, convolution) separately allows clipping to be performed in conjunction with backpropagation. This results in private learning that is as memory-efficient and almost as timeefficient per training update as non-private learning for many small to moderate scale workflows of practical interest. While per-layer clipping with static clipping thresholds chosen by hand tends to underperform flat clipping, we show that per-layer clipping with adaptively estimated thresholds matches or outperforms flat clipping under given training epoch constraints, hence attaining similar or better task performances with less wall time. DP-SGD is known to (possibly) incur substantial performance losses compared to non-private learning. To improve the privacy-utility trade-off, several past works have leveraged large-scale publicly pretrained models (Yu et al., 2022; Li et al., 2022b; De et al., 2022; Mehta et al., 2022). These works observe that the privacy-utility trade-off improves with the use of larger (and thus better) pretrained models.1 We extend this research and study a second research question Can the privacy-utility trade-off be further improved with even better / larger pretrained models? To study this, we scale DP fine-tuning to work with one of the largest and most performant pretrained language models to date\u2014the 175 billion-parameter GPT-3. Weights of this model cannot be hosted in the memory of a single accelerator (e.g., GPU) and must be distributed across multiple devices. This presents challenges for flat clipping which calls for communicating per-example gradient norms across devices. To bypass these challenges, we turn to per-device clipping, where each device is prescribed a clipping threshold for clipping per-example gradients of the hosted model piece. Per-device clipping incurs no additional communication cost and allowed us to obtain with GPT-3 a private fine-tuning performance at \u03f5 = 1 that is better than what is attainable by non-privately fine-tuning the largest GPT-2 on a challenging summarization task. Our contributions are summarized below. (1) We show per-layer clipping enables clipping to be done in conjunction with backpropagation in DP optimization and results in private learning that is as memory-efficient and almost as fast per training update as non-private learning for many small to moderate scale workflows of interest. (2) We show adaptive per-layer clipping matches or outperforms flat clipping under fixed training epoch constraints, and thus attains similar or better task performances with less wall time. (3) We bypass scaling challenges associated with communicating per-example gradient norms with per-device clipping, with which we scale DP fine-tuning to work with the 175 billion-parameter GPT-3 and obtain improved task performance for a challenging summarization task at \u03f5 = 1. Finish the entire review and DO NOT STOP in the middle. GIVE A FINAL DECISION in the form of 'FINAL DECISION: <Accept/Reject>'.\",\n  \"agent_name\": \"ReviewerThree\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AskAgent', response={'result': {'status': 'success', 'message': 'Agent has replied to the given prompt', 'output': '## Review of \"Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping\"\\n\\nThis paper explores the computational efficiency and privacy-utility trade-offs of differentially private deep learning (DP-DL) using group-wise clipping strategies. The authors investigate two main research questions: 1) Can private learning be as memory and time efficient as non-private learning? and 2) Can the privacy-utility trade-off be further improved with larger pretrained models? They propose and evaluate per-layer and per-device clipping strategies within the DP-SGD framework to address these questions.\\n\\n**Strengths:**\\n\\n*   **Addresses Important Problems:** The paper tackles two crucial challenges in DP-DL: computational overhead and utility degradation. These are significant bottlenecks that hinder the wider adoption of DP-DL in practice.\\n*   **Clear Research Questions and Contributions:** The research questions are clearly defined, and the contributions are well-articulated in the introduction and conclusion.\\n*   **Practical and Scalable Solutions:** The proposed per-layer and per-device clipping strategies offer practical solutions for improving computational efficiency and scaling DP-DL to large models.  The focus on memory efficiency is particularly valuable.\\n*   **Strong Experimental Results:** The experimental results support the claims made in the paper. The authors demonstrate that per-layer clipping can achieve comparable or better performance than flat clipping with reduced computational overhead. They also showcase the successful application of per-device clipping to fine-tune GPT-3, achieving state-of-the-art results in private fine-tuning. The experiments cover a range of datasets and model sizes.\\n*   **Well-written and Organized:** The paper is generally well-written and organized, making it easy to follow the authors\\' reasoning and understand their contributions.\\n*   **Impactful Application:**  Demonstrating DP fine-tuning of GPT-3 is a significant achievement and a strong contribution to the field. This highlights the potential of the proposed methods for real-world applications.\\n\\n**Weaknesses:**\\n\\n*   **Limited Theoretical Analysis:** While the paper presents strong empirical results, the theoretical analysis of the proposed clipping strategies is limited.  A deeper understanding of the privacy implications and convergence properties of per-layer and per-device clipping could further strengthen the paper.  For example, is there a theoretical reason to believe adaptive per-layer clipping can match or outperform flat clipping?\\n*   **Adaptive Clipping Threshold Tuning:**  The details of how the adaptive clipping thresholds are chosen for per-layer clipping could be expanded. The sensitivity of the performance to the choice of adaptive clipping method should be discussed, potentially including ablation studies of different strategies.\\n*   **Hyperparameter Sensitivity:**  The paper could benefit from a more detailed discussion on the sensitivity of the results to different hyperparameters, such as the clipping norm, learning rate, and noise multiplier. Providing guidelines for choosing these hyperparameters for different datasets and models would be valuable for practitioners.\\n*   **Comparison to Alternative DP-SGD Optimizations:** The related work section mentions several recent works on improving DP-SGD. While the paper compares against flat clipping (a common baseline), it would be beneficial to explicitly compare the proposed methods against other state-of-the-art DP-SGD optimization techniques in terms of both computational efficiency and privacy-utility trade-off.\\n\\n**Overall Assessment:**\\n\\nThis paper presents a valuable contribution to the field of differentially private deep learning. The proposed per-layer and per-device clipping strategies offer practical solutions for improving computational efficiency and scaling DP-DL to large models. The experimental results are strong and support the claims made in the paper. While the theoretical analysis could be strengthened and the hyperparameter sensitivity could be discussed in more detail, the paper\\'s practical impact and clear presentation make it a strong candidate for acceptance.\\n\\n**FINAL DECISION: Accept**\\n', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9.844431095}}), inline_data=None, text=None)], role='tool')"}, {"role": "assistant", "content": "All three reviewers recommend accepting the paper. They highlight the practical contributions of the paper, particularly the efficient implementation of per-layer clipping and the successful application of per-device clipping to fine-tune GPT-3 under differential privacy. The reviewers also point out the need for more theoretical analysis and a more detailed discussion of hyperparameter sensitivity.\n\n**FINAL DECISION: Accept**\n"}], "ground_truth": "Accept: poster", "response_time": 949.1040980815887}
